{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "531c9fb8-bd3c-4cd3-b8b7-39447043554a",
   "metadata": {},
   "source": [
    "# Preprocessing of ML 4523 Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a441cf3-b4c8-479b-873e-047726046f4d",
   "metadata": {},
   "source": [
    "## Importing Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "c2ba09d8-6f34-4330-b96d-a52b3a949f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic Imports:\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk import word_tokenize\n",
    "from nltk import pos_tag\n",
    "import re\n",
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# Preprocessing Imports\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.preprocessing as preproc\n",
    "from sklearn.feature_extraction import text\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from random import shuffle\n",
    "import random\n",
    "random.seed(123)\n",
    "from utils.syntactic_similarity_measures import SyntacticMeasures\n",
    "from utils.lesk_algorithm import Lesk\n",
    "from utils.semantic_similarity_measures import SemanticMeasures\n",
    "from utils.wordnet import GetWordnetPos\n",
    "from pre_processor import Preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc27e460-3d47-4464-9ace-a219853b1b26",
   "metadata": {},
   "source": [
    "## Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6e61579-201a-4cec-b0b4-58eaba0c966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of contractions from http://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python\n",
    "contractions = { \n",
    "\"ain't\": \"am not\",\n",
    "\"aren't\": \"are not\",\n",
    "\"can't\": \"cannot\",\n",
    "\"can't've\": \"cannot have\",\n",
    "\"'cause\": \"because\",\n",
    "\"could've\": \"could have\",\n",
    "\"couldn't\": \"could not\",\n",
    "\"couldn't've\": \"could not have\",\n",
    "\"didn't\": \"did not\",\n",
    "\"doesn't\": \"does not\",\n",
    "\"don't\": \"do not\",\n",
    "\"hadn't\": \"had not\",\n",
    "\"hadn't've\": \"had not have\",\n",
    "\"hasn't\": \"has not\",\n",
    "\"haven't\": \"have not\",\n",
    "\"he'd\": \"he would\",\n",
    "\"he'd've\": \"he would have\",\n",
    "\"he'll\": \"he will\",\n",
    "\"he's\": \"he is\",\n",
    "\"how'd\": \"how did\",\n",
    "\"how'll\": \"how will\",\n",
    "\"how's\": \"how is\",\n",
    "\"i'd\": \"i would\",\n",
    "\"i'll\": \"i will\",\n",
    "\"i'm\": \"i am\",\n",
    "\"i've\": \"i have\",\n",
    "\"isn't\": \"is not\",\n",
    "\"it'd\": \"it would\",\n",
    "\"it'll\": \"it will\",\n",
    "\"it's\": \"it is\",\n",
    "\"let's\": \"let us\",\n",
    "\"ma'am\": \"madam\",\n",
    "\"mayn't\": \"may not\",\n",
    "\"might've\": \"might have\",\n",
    "\"mightn't\": \"might not\",\n",
    "\"must've\": \"must have\",\n",
    "\"mustn't\": \"must not\",\n",
    "\"needn't\": \"need not\",\n",
    "\"oughtn't\": \"ought not\",\n",
    "\"shan't\": \"shall not\",\n",
    "\"sha'n't\": \"shall not\",\n",
    "\"she'd\": \"she would\",\n",
    "\"she'll\": \"she will\",\n",
    "\"she's\": \"she is\",\n",
    "\"should've\": \"should have\",\n",
    "\"shouldn't\": \"should not\",\n",
    "\"that'd\": \"that would\",\n",
    "\"that's\": \"that is\",\n",
    "\"there'd\": \"there had\",\n",
    "\"there's\": \"there is\",\n",
    "\"they'd\": \"they would\",\n",
    "\"they'll\": \"they will\",\n",
    "\"they're\": \"they are\",\n",
    "\"they've\": \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\": \"we would\",\n",
    "\"we'll\": \"we will\",\n",
    "\"we're\": \"we are\",\n",
    "\"we've\": \"we have\",\n",
    "\"weren't\": \"were not\",\n",
    "\"what'll\": \"what will\",\n",
    "\"what're\": \"what are\",\n",
    "\"what's\": \"what is\",\n",
    "\"what've\": \"what have\",\n",
    "\"where'd\": \"where did\",\n",
    "\"where's\": \"where is\",\n",
    "\"who'll\": \"who will\",\n",
    "\"who's\": \"who is\",\n",
    "\"won't\": \"will not\",\n",
    "\"wouldn't\": \"would not\",\n",
    "\"you'd\": \"you would\",\n",
    "\"you'll\": \"you will\",\n",
    "\"you're\": \"you are\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fdd0538-6032-490d-9087-b717b9b5a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text, remove_stopwords = True):\n",
    "    '''Remove unwanted characters, stopwords, and format the text to create fewer nulls word embeddings'''\n",
    "    \n",
    "    # Convert words to lower case\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Replace contractions with their longer forms \n",
    "    if True:\n",
    "        text = text.split()\n",
    "        new_text = []\n",
    "        for word in text:\n",
    "            if word in contractions:\n",
    "                new_text.append(contractions[word])\n",
    "            else:\n",
    "                new_text.append(word)\n",
    "        text = \" \".join(new_text)\n",
    "    \n",
    "    # Format words and remove unwanted characters\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\<a href', ' ', text)\n",
    "    text = re.sub(r'&amp;', '', text) \n",
    "    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]/]', ' ', text)\n",
    "    text = re.sub(r'<br />', ' ', text)\n",
    "    text = re.sub(r'\\'', ' ', text)\n",
    "    \n",
    "    # remove stop words\n",
    "    if remove_stopwords:\n",
    "        text = text.split()\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "        text = \" \".join(text)\n",
    "\n",
    "    # Tokenize each word\n",
    "    text =  nltk.WordPunctTokenizer().tokenize(text)\n",
    "        \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6554ca31-d2e0-4889-abb5-52c8f4e9d75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter_cosine_similarity(token1, token2):\n",
    "    c1 = Counter(token1)\n",
    "    c2 = Counter(token2)\n",
    "    terms = set(c1).union(c2)\n",
    "    dotprod = sum(c1.get(k, 0) * c2.get(k, 0) for k in terms)\n",
    "    magA = math.sqrt(sum(c1.get(k, 0)**2 for k in terms))\n",
    "    magB = math.sqrt(sum(c2.get(k, 0)**2 for k in terms))\n",
    "    return dotprod / (magA * magB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8d918c9-7d08-46dd-a536-c6ed9c2837d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length_similarity(token1, token2):\n",
    "    c1 = Counter(token1)\n",
    "    c2 = Counter(token2)\n",
    "    lenc1 = sum(iter(c1.values()))\n",
    "    lenc2 = sum(iter(c2.values()))\n",
    "    lengthSim = min(lenc1, lenc2) / float(max(lenc1, lenc2))\n",
    "    return lengthSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a0a26088-7643-4924-a322-140906c884fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap_score(token1, token2):\n",
    "    c1 = Counter(token1)\n",
    "    c2 = Counter(token2)\n",
    "    lenc1 = sum(iter(c1.values()))\n",
    "    lenc2 = sum(iter(c2.values()))\n",
    "    overlappingtermsCount = sum(((c1)&(c2)).values())\n",
    "    overlap_score = abs((overlappingtermsCount/lenc1) - (overlappingtermsCount/lenc2))\n",
    "    return overlap_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4d22e67a-375e-4522-9ea8-d23f8bb632c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overlap2_score(token1, token2):\n",
    "    c1 = Counter(token1)\n",
    "    c2 = Counter(token2)\n",
    "    lenc1 = sum(iter(c1.values()))\n",
    "    lenc2 = sum(iter(c2.values()))\n",
    "    overlappingtermsCount = sum(((c1)&(c2)).values())\n",
    "    overlap2_score = (overlappingtermsCount/(lenc1+lenc2))\n",
    "    return overlap2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2fa097b5-776a-4f36-adcc-8a036368b132",
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(lengthSim,cosine_score):\n",
    "    return lengthSim*cosine_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4bfbffb7-2374-4ad9-a337-8dc51d912a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cosine_similarity(token1, token2):\n",
    "        \"\"\" compute cosine similarity \"\"\"\n",
    "        cosine_similarity = SyntacticMeasures.getCosineSimilarity(token1,token2)\n",
    "        return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4748ccc0-b6f4-493f-b647-46045bc823a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_jaccard_similarity(token1, token2):\n",
    "        \"\"\" compute jaccard similarity\"\"\"\n",
    "        jaccard_similarity = SyntacticMeasures.normal_jaccard_distance(token1,token2)\n",
    "        return jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1182cf48-c033-42d9-9293-0524631d732c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_lemma_jaccard_similarity(lemma1, lemma2):\n",
    "        \"\"\" compute lemma jaccard similarity\"\"\"\n",
    "        lemma_jaccard_similarity = SyntacticMeasures.lemma_jaccard_distance(lemma1,lemma2)\n",
    "        return lemma_jaccard_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8c442b9-7c36-4114-a155-cb069522f8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_combined_score_syn(r1, r2, r3):\n",
    "        \"\"\" get the combined score\"\"\"\n",
    "        return (r1+r2+r3)/ 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e0c15ef0-7891-4ecd-9346-c59e1abc3654",
   "metadata": {},
   "outputs": [],
   "source": [
    "def overall_similarity_combined(token1, token2, lemma1, lemma2):\n",
    "        \"\"\" calculate combined similarity \"\"\"\n",
    "\n",
    "        R1 = compute_cosine_similarity(token1,token2)\n",
    "        R2 = compute_jaccard_similarity(token1,token2)\n",
    "        R3 = compute_lemma_jaccard_similarity(lemma1,lemma2)\n",
    "        R = compute_combined_score_syn(R1,R2,R3)\n",
    "        return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a493415-34d8-44e7-a4bf-9a6f03cb1474",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_lesk(ques):\n",
    "        \"\"\" get each word meaning out of the given question\"\"\"\n",
    "        lesk_obj = Lesk(ques)\n",
    "        sentence_means = []\n",
    "        for word in ques:\n",
    "            sentence_means.append(lesk_obj.lesk(word, ques))\n",
    "        return sentence_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "96753c69-018b-43a0-8e26-a7fdb30766ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def semantic_similarities(token1, token2):\n",
    "    sentence_means1 = get_lesk(token1)\n",
    "    sentence_means2 = get_lesk(token2)\n",
    "    \n",
    "    RWUP = SemanticMeasures.computeWup(sentence_means1, sentence_means2)\n",
    "    OverallWUP = SemanticMeasures.overallSim(sentence_means1, sentence_means2, RWUP)\n",
    "    RSIM = SemanticMeasures.computePath(sentence_means1, sentence_means2)\n",
    "    OverallSIM = SemanticMeasures.overallSim(sentence_means1, sentence_means2, RSIM)\n",
    "    RCOMBINED = (RWUP + RSIM)/2\n",
    "    OverallCombined = SemanticMeasures.overallSim(sentence_means1, sentence_means2, RCOMBINED)\n",
    "    \n",
    "    score_list = [OverallWUP,OverallSIM, OverallCombined]\n",
    "    return score_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64da0999-d0a8-4cd2-97d9-e192cc4b42bb",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "09d56745-8dfb-4ff2-9e24-adc845612496",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../Data/train_with_label.txt\", delimiter = \"r'\\t\", header = None, engine = 'python')\n",
    "train_df = train_df[0].str.split(\"\\t\", expand=True)\n",
    "train_df = train_df.rename(columns={0: \"id\", 1: \"sentence1\", 2: \"sentence2\", 3: \"classification\"})\n",
    "train_df[\"classification\"] = pd.to_numeric(train_df[\"classification\"])\n",
    "train_df.drop_duplicates(inplace = True)\n",
    "train_df\n",
    "\n",
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#Syntactic Features:\n",
    "train_df['Text_Cleaned1'] = list(map(clean_text, train_df.sentence1))\n",
    "train_df['lemmatized_text1'] = list(map(lambda word:list(map(lemm.lemmatize, word)),train_df.Text_Cleaned1))\n",
    "train_df['Text_Cleaned2'] = list(map(clean_text, train_df.sentence2))\n",
    "train_df['lemmatized_text2'] = list(map(lambda word:list(map(lemm.lemmatize, word)),train_df.Text_Cleaned2))\n",
    "train_df['cosine_similarity_score'] = list(map(counter_cosine_similarity, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['length_similarity'] = list(map(length_similarity, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['overlap_score'] = list(map(overlap_score, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['overlap2_score'] = list(map(overlap2_score, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['cosine/length_ratio'] = list(map(similarity_score, train_df.length_similarity, train_df.cosine_similarity_score))\n",
    "train_df['cosine_similarity_score2'] = list(map(compute_cosine_similarity, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['jaccard_similarity_score'] = list(map(compute_jaccard_similarity, train_df.Text_Cleaned1, train_df.Text_Cleaned2))\n",
    "train_df['lemma_jaccard_score'] = list(map(compute_lemma_jaccard_similarity, train_df.lemmatized_text1, train_df.lemmatized_text2))\n",
    "train_df['overall_sim_score'] = list(map(overall_similarity_combined, train_df.Text_Cleaned1, train_df.Text_Cleaned2, train_df.lemmatized_text1, train_df.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "0622a231-43ae-46f0-81db-5f0b5f3cafdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Semantic Features:\n",
    "df1 = train_df.iloc[:800]\n",
    "df2 = train_df.iloc[800:1600]\n",
    "df3 = train_df.iloc[1600:2400]\n",
    "df4 = train_df.iloc[2400:3200]\n",
    "df5 = train_df.iloc[3200:4077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "9ff67528-e280-46ec-8338-8cf121f77e7c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df1['scores'] = list(map(semantic_similarities, df1.lemmatized_text1, df1.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e5892e23-06e8-479e-9ece-4b3868b1098d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2['scores'] = list(map(semantic_similarities, df2.lemmatized_text1, df2.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3ba07068-4f4f-4860-805c-780aa0c69794",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['scores'] = list(map(semantic_similarities, df3.lemmatized_text1, df3.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "429aedcd-2b5f-4c2d-9dad-f221ed74e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['scores'] = list(map(semantic_similarities, df4.lemmatized_text1, df4.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1ce4b1fd-8dd6-41b0-92a5-b81d3e3246c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['scores'] = list(map(semantic_similarities, df5.lemmatized_text1, df5.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f752872f-5225-4ee6-b56e-a847d243e0ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.055147</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.856008</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.915825</td>\n",
       "      <td>0.917869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>0.954786</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>0.873775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>[said, problem, needs, corrected, space, shutt...</td>\n",
       "      <td>[said, problem, need, corrected, space, shuttl...</td>\n",
       "      <td>[said, prob, lem, needs, corrected, space, shu...</td>\n",
       "      <td>[said, prob, lem, need, corrected, space, shut...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.825926</td>\n",
       "      <td>0.741799</td>\n",
       "      <td>0.780159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.541266</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.659046</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.806662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.534127</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.504819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[mrs, clinton, decide, contest, 2008, election...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "      <td>0.819892</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.799178</td>\n",
       "      <td>0.791613</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.758261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1</td>\n",
       "      <td>[iranian, refugee, sewed, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, refugee, sewed, eye, lip, ear, prote...</td>\n",
       "      <td>[iranian, kurd, stitched, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, kurd, stitched, eye, lip, ear, prote...</td>\n",
       "      <td>0.560449</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.517337</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.631617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[gemstar, shares, gathered, 2, 6, percent, add...</td>\n",
       "      <td>[gemstar, share, gathered, 2, 6, percent, addi...</td>\n",
       "      <td>[gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, share, moved, higher, news, closing,...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>0.592460</td>\n",
       "      <td>0.631049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4077 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...               1   \n",
       "1     The woman was exposed to the SARS virus while ...               1   \n",
       "2     He said the prob lem needs to be corrected bef...               1   \n",
       "3     Anthony Citrano , a representative for WhenU ,...               0   \n",
       "4     The biggest threat to order seemed to be looti...               1   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...               1   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...               1   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...               1   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...               1   \n",
       "4076  Gemstar shares moved higher on the news , clos...               1   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, needs, corrected, space, shutt...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, gathered, 2, 6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, need, corrected, space, shuttl...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, gathered, 2, 6, percent, addi...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, needs, corrected, space, shu...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mrs, clinton, decide, contest, 2008, election...   \n",
       "4075  [iranian, kurd, stitched, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, need, corrected, space, shut...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...   \n",
       "4075  [iranian, kurd, stitched, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, moved, higher, news, closing,...   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                    0.909509           0.941176       0.055147   \n",
       "1                    0.904534           0.888889       0.111111   \n",
       "2                    0.666667           1.000000       0.000000   \n",
       "3                    0.455842           0.636364       0.207792   \n",
       "4                    0.721688           0.750000       0.208333   \n",
       "...                       ...                ...            ...   \n",
       "4072                 0.805823           0.750000       0.222222   \n",
       "4073                 0.600000           1.000000       0.000000   \n",
       "4074                 0.819892           0.923077       0.064103   \n",
       "4075                 0.560449           0.923077       0.044872   \n",
       "4076                 0.583333           1.000000       0.000000   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0           0.454545             0.856008                  0.970143   \n",
       "1           0.470588             0.804030                  0.954786   \n",
       "2           0.333333             0.666667                  1.000000   \n",
       "3           0.222222             0.290081                  0.797724   \n",
       "4           0.357143             0.541266                  0.866025   \n",
       "...              ...                  ...                       ...   \n",
       "4072        0.380952             0.604367                  0.886405   \n",
       "4073        0.300000             0.600000                  1.000000   \n",
       "4074        0.400000             0.756823                  0.968963   \n",
       "4075        0.280000             0.517337                  0.960769   \n",
       "4076        0.291667             0.583333                  1.000000   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "0                     0.833333             0.833333           0.878936   \n",
       "1                     0.937500             0.937500           0.943262   \n",
       "2                     0.500000             0.636364           0.712121   \n",
       "3                     0.285714             0.285714           0.456384   \n",
       "4                     0.555556             0.555556           0.659046   \n",
       "...                        ...                  ...                ...   \n",
       "4072                  0.583333             0.583333           0.684357   \n",
       "4073                  0.428571             0.538462           0.655678   \n",
       "4074                  0.714286             0.714286           0.799178   \n",
       "4075                  0.388889             0.388889           0.579516   \n",
       "4076                  0.411765             0.411765           0.607843   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "0                             0.919913                         0.915825   \n",
       "1                             0.870098                         0.877451   \n",
       "2                             0.825926                         0.741799   \n",
       "3                             0.681597                         0.526984   \n",
       "4                             0.818681                         0.794643   \n",
       "...                                ...                              ...   \n",
       "4072                          0.534127                         0.485714   \n",
       "4073                          0.883333                         0.883333   \n",
       "4074                          0.791613                         0.740000   \n",
       "4075                          0.700889                         0.562857   \n",
       "4076                          0.687302                         0.592460   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "0                                 0.917869  \n",
       "1                                 0.873775  \n",
       "2                                 0.780159  \n",
       "3                                 0.577681  \n",
       "4                                 0.806662  \n",
       "...                                    ...  \n",
       "4072                              0.504819  \n",
       "4073                              0.883333  \n",
       "4074                              0.758261  \n",
       "4075                              0.631617  \n",
       "4076                              0.631049  \n",
       "\n",
       "[4077 rows x 20 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = df1.append(df2).append(df3).append(df4).append(df5)\n",
    "train_df[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']] = pd.DataFrame(train_df.scores.tolist(), index= train_df.index)\n",
    "train_df.drop(['scores'], axis=1, inplace=True)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4dcd3b-4629-4ef4-adff-c0db5bbbf7c4",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class Normal Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "fac61205-e46e-4e71-9204-88e9c3d0e962",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "subset0 = train_df.loc[train_df['classification'] == 0]\n",
    "subset1 = train_df.loc[train_df['classification'] == 1]\n",
    "subset1Sample = subset1.sample(n=1039,random_state=42)\n",
    "new_train_df = subset0.append(subset1Sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82005df1-0bea-4018-b679-d479ae7fda75",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset with Outliers Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "403aad28-1187-43e3-9b9e-06eeab71fca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_outliers(df,column_name,lower,upper):\n",
    "    removed_outliers = df[column_name].between(df[column_name].quantile(lower), df[column_name].quantile(upper))\n",
    "    index_names = df[~removed_outliers].index # INVERT removed_outliers!!\n",
    "    return df.drop(index_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "20b0a9e1-c52a-487e-a649-55b8dd67bf7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "640"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset0_clean = remove_outliers(subset0, 'cosine_similarity_score', .05,.95)\n",
    "# #subset0_clean = remove_outliers(subset0_clean, 'length_similarity', .05,.95)\n",
    "subset0_clean = remove_outliers(subset0, 'overlap_score', .00,.90)\n",
    "# subset0_clean = remove_outliers(subset0_clean, 'overlap2_score', .05,.95)\n",
    "subset0_clean = remove_outliers(subset0_clean, 'cosine/length_ratio', .00,.90)\n",
    "# #subset0_clean = remove_outliers(subset0_clean, 'cosine_similarity_score2', .05,.95)\n",
    "subset0_clean = remove_outliers(subset0_clean, 'jaccard_similarity_score', .00,.90)\n",
    "subset0_clean = remove_outliers(subset0_clean, 'lemma_jaccard_score', .00,.90)\n",
    "subset0_clean = remove_outliers(subset0_clean, 'overall_sim_score', .00,.90)\n",
    "# subset0_clean = remove_outliers(subset0_clean, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'bigram_similarity',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'jaccard_distance_trigrams',.05,.95)\n",
    "subset0_clean = remove_outliers(subset0_clean,'cosine_similarity_trigrams', .00,.90)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'trigram_similarity',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset0_clean = remove_outliers(subset0_clean,'quadgram_similarity',.05,.95)\n",
    "\n",
    "len(subset0_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "57172ba0-df42-4efd-a5f0-7f9d5165abf6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1650"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset1_clean = remove_outliers(subset1, 'cosine_similarity_score', .05,.95)\n",
    "# # subset1_clean = remove_outliers(subset1_clean, 'length_similarity', .05,.95)\n",
    "subset1_clean = remove_outliers(subset1, 'overlap_score', .10,1.0)\n",
    "# subset1_clean = remove_outliers(subset1_clean, 'overlap2_score', .05,.95)\n",
    "subset1_clean = remove_outliers(subset1_clean, 'cosine/length_ratio', .10,1.0)\n",
    "# #subset1_clean = remove_outliers(subset1_clean, 'cosine_similarity_score2', .05,.95)\n",
    "subset1_clean = remove_outliers(subset1_clean, 'jaccard_similarity_score', .10,1.0)\n",
    "subset1_clean = remove_outliers(subset1_clean, 'lemma_jaccard_score', .10,1.0)\n",
    "subset1_clean = remove_outliers(subset1_clean, 'overall_sim_score', .10,1.0)\n",
    "# subset1_clean = remove_outliers(subset1_clean, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'bigram_similarity',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'jaccard_distance_trigrams',.05,.95)\n",
    "subset1_clean = remove_outliers(subset1_clean,'cosine_similarity_trigrams',.10,1.0)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'trigram_similarity',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset1_clean = remove_outliers(subset1_clean,'quadgram_similarity',.05,.95)\n",
    "len(subset1_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "f3c12ec3-a9cb-4c79-b8eb-5db1829288b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.551413</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.801136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.870857</td>\n",
       "      <td>0.890264</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4064</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.643223</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.335410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.799178</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2290 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.285714           0.456384   \n",
       "7                  0             0.411765           0.530084   \n",
       "8                  0             0.388889           0.551413   \n",
       "11                 0             0.200000           0.431476   \n",
       "17                 0             0.380952           0.472186   \n",
       "...              ...                  ...                ...   \n",
       "4063               1             0.833333           0.870857   \n",
       "4064               1             0.500000           0.643223   \n",
       "4072               1             0.583333           0.684357   \n",
       "4073               1             0.538462           0.655678   \n",
       "4074               1             0.714286           0.799178   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.149071   \n",
       "7                0.362209                    0.204124   \n",
       "8                0.324459                    0.267261   \n",
       "11               0.268328                    0.000000   \n",
       "17               0.360060                    0.000000   \n",
       "...                   ...                         ...   \n",
       "4063             0.890264                    0.733333   \n",
       "4064             0.493007                    0.335410   \n",
       "4072             0.604367                    0.239046   \n",
       "4073             0.600000                    0.375000   \n",
       "4074             0.756823                    0.476731   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.333333       0.828571  \n",
       "8                     0.388889       0.801136  \n",
       "11                    0.200000       0.925000  \n",
       "17                    0.380952       0.700000  \n",
       "...                        ...            ...  \n",
       "4063                  0.833333       1.000000  \n",
       "4064                  0.500000       0.883333  \n",
       "4072                  0.583333       0.777778  \n",
       "4073                  0.428571       1.000000  \n",
       "4074                  0.714286       0.935897  \n",
       "\n",
       "[2290 rows x 7 columns]"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df_clean = subset0_clean.append(subset1_clean)\n",
    "new_train_df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e36e70-a89e-45a8-a64d-42727f7fab90",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Undersampled Normal Training Dataset Using ImbLearn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81de65bf-05d8-4216-b609-e24af73217b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043600eb-2dd3-46b9-b58a-6e9c15ef1afa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f18762e6-e70f-4c39-abda-d9d6d69a2f65",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset with Other Preprocessing Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5200fd9a-a153-4ef7-bf2b-e5456ec9ea95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thePreprocessorNoLemma(token1):\n",
    "    processor = Preprocess(token1)\n",
    "    token = processor.preprocess_without_lemma()\n",
    "    return token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "fda9038a-2d2a-4c1c-a30d-1977a481cf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def thePreprocessorLemma(lemma1):\n",
    "    processor = Preprocess(lemma1)\n",
    "    lemma_token = processor.preprocess_with_lemma()\n",
    "    return lemma_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "f2005782-05a4-45c8-be3e-c8cf31373143",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health,...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, said, problem, needs, corrected, space, s...</td>\n",
       "      <td>[He, said, prob, lem, needs, corrected, space,...</td>\n",
       "      <td>[say, problem, need, correct, space, shuttle, ...</td>\n",
       "      <td>[say, prob, lem, need, correct, space, shuttle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[A, representative, Phoenix-based, U-Haul, dec...</td>\n",
       "      <td>[Anthony, Citrano, representative, WhenU, decl...</td>\n",
       "      <td>[representative, phoenix-based, u-haul, declin...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[Axelrod, died, heart, failure, asleep, Los, A...</td>\n",
       "      <td>[axelrod, die, sleep, heart, failure, say, dau...</td>\n",
       "      <td>[axelrod, die, heart, failure, asleep, los, an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Saddam, 's, son, Odai, surrendered, Friday, A...</td>\n",
       "      <td>[Hussein, 's, son, Uday, surrendered, yesterda...</td>\n",
       "      <td>[saddam, 's, son, odai, surrender, friday, ame...</td>\n",
       "      <td>[hussein, 's, son, uday, surrender, yesterday,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1</td>\n",
       "      <td>[If, Senator, Clinton, decide, run, 2008, anno...</td>\n",
       "      <td>[If, Mrs, Clinton, decide, contest, 2008, elec...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, announce...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Iranian, refugee, sewed, eyes, lips, ear...</td>\n",
       "      <td>[An, Iranian, Kurd, stitched, eyes, lips, ears...</td>\n",
       "      <td>[iranian, refugee, sew, eye, lip, ear, protest...</td>\n",
       "      <td>[iranian, kurd, stitch, eye, lip, ear, protest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Gemstar, 's, shares, gathered, 2.6, percent, ...</td>\n",
       "      <td>[Gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, 's, share, gather, 2.6, percent, add...</td>\n",
       "      <td>[gemstar, share, move, higher, news, close, 2....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4077 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...               1   \n",
       "1     The woman was exposed to the SARS virus while ...               1   \n",
       "2     He said the prob lem needs to be corrected bef...               1   \n",
       "3     Anthony Citrano , a representative for WhenU ,...               0   \n",
       "4     The biggest threat to order seemed to be looti...               1   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...               1   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...               1   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...               1   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...               1   \n",
       "4076  Gemstar shares moved higher on the news , clos...               1   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, problem, needs, corrected, space, s...   \n",
       "3     [A, representative, Phoenix-based, U-Haul, dec...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [Saddam, 's, son, Odai, surrendered, Friday, A...   \n",
       "4074  [If, Senator, Clinton, decide, run, 2008, anno...   \n",
       "4075  [The, Iranian, refugee, sewed, eyes, lips, ear...   \n",
       "4076  [Gemstar, 's, shares, gathered, 2.6, percent, ...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, prob, lem, needs, corrected, space,...   \n",
       "3     [Anthony, Citrano, representative, WhenU, decl...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, heart, failure, asleep, Los, A...   \n",
       "4073  [Hussein, 's, son, Uday, surrendered, yesterda...   \n",
       "4074  [If, Mrs, Clinton, decide, contest, 2008, elec...   \n",
       "4075  [An, Iranian, Kurd, stitched, eyes, lips, ears...   \n",
       "4076  [Gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, begin, announce,...   \n",
       "1     [woman, expose, sars, virus, hospital, health,...   \n",
       "2     [say, problem, need, correct, space, shuttle, ...   \n",
       "3     [representative, phoenix-based, u-haul, declin...   \n",
       "4     [big, threat, order, seem, loot, crime, includ...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, die, sleep, heart, failure, say, dau...   \n",
       "4073  [saddam, 's, son, odai, surrender, friday, ame...   \n",
       "4074  [senator, clinton, decide, run, 2008, announce...   \n",
       "4075  [iranian, refugee, sew, eye, lip, ear, protest...   \n",
       "4076  [gemstar, 's, share, gather, 2.6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text2  \n",
       "0     [democratic, candidate, also, begin, announce,...  \n",
       "1     [woman, expose, sars, virus, hospital, health-...  \n",
       "2     [say, prob, lem, need, correct, space, shuttle...  \n",
       "3     [anthony, citrano, representative, whenu, decl...  \n",
       "4     [big, threat, order, seem, loot, crime, includ...  \n",
       "...                                                 ...  \n",
       "4072  [axelrod, die, heart, failure, asleep, los, an...  \n",
       "4073  [hussein, 's, son, uday, surrender, yesterday,...  \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...  \n",
       "4075  [iranian, kurd, stitch, eye, lip, ear, protest...  \n",
       "4076  [gemstar, share, move, higher, news, close, 2....  \n",
       "\n",
       "[4077 rows x 8 columns]"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2 = pd.read_csv(\"../Data/train_with_label.txt\", delimiter = \"r'\\t\", header = None, engine = 'python')\n",
    "train_df2 = train_df2[0].str.split(\"\\t\", expand=True)\n",
    "train_df2 = train_df2.rename(columns={0: \"id\", 1: \"sentence1\", 2: \"sentence2\", 3: \"classification\"})\n",
    "train_df2[\"classification\"] = pd.to_numeric(train_df2[\"classification\"])\n",
    "train_df2.drop_duplicates(inplace = True)\n",
    "train_df2\n",
    "\n",
    "#Text Cleaning Features:\n",
    "train_df2['Text_Cleaned1'] = list(map(thePreprocessorNoLemma, train_df2.sentence1))\n",
    "train_df2['Text_Cleaned2'] = list(map(thePreprocessorNoLemma, train_df2.sentence2))\n",
    "train_df2['lemmatized_text1'] = list(map(thePreprocessorLemma, train_df2.sentence1))\n",
    "train_df2['lemmatized_text2'] = list(map(thePreprocessorLemma, train_df2.sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "aa2ed4f4-8886-4a6e-bbfa-636c1a6400d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntactic Features:\n",
    "train_df2['cosine_similarity_score'] = list(map(counter_cosine_similarity, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['length_similarity'] = list(map(length_similarity, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['overlap_score'] = list(map(overlap_score, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['overlap2_score'] = list(map(overlap2_score, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['cosine/length_ratio'] = list(map(similarity_score, train_df2.length_similarity, train_df2.cosine_similarity_score))\n",
    "train_df2['cosine_similarity_score2'] = list(map(compute_cosine_similarity, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['jaccard_similarity_score'] = list(map(compute_jaccard_similarity, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2))\n",
    "train_df2['lemma_jaccard_score'] = list(map(compute_lemma_jaccard_similarity, train_df2.lemmatized_text1, train_df2.lemmatized_text2))\n",
    "train_df2['overall_sim_score'] = list(map(overall_similarity_combined, train_df2.Text_Cleaned1, train_df2.Text_Cleaned2, train_df2.lemmatized_text1, train_df2.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "8ca5ce40-da9a-45dd-88cd-f0fc6cd4572a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Semantic Features:\n",
    "pdf1 = train_df2.iloc[:800]\n",
    "pdf2 = train_df2.iloc[800:1600]\n",
    "pdf3 = train_df2.iloc[1600:2400]\n",
    "pdf4 = train_df2.iloc[2400:3200]\n",
    "pdf5 = train_df2.iloc[3200:4077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "b62ddb84-dcac-41a3-90a4-e984730ca393",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1['scores'] = list(map(semantic_similarities, pdf1.lemmatized_text1, pdf1.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9c999b93-028a-4d2b-9ed1-3119fec100c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2['scores'] = list(map(semantic_similarities, pdf2.lemmatized_text1, pdf2.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "b7750822-b1e3-423f-a537-d90ef34d3643",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3['scores'] = list(map(semantic_similarities, pdf3.lemmatized_text1, pdf3.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "5f405fee-5e20-4017-87dc-75512590fb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4['scores'] = list(map(semantic_similarities, pdf4.lemmatized_text1, pdf4.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "47ab3f3d-d23b-4ea6-bb20-9ce92fbf8d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf5['scores'] = list(map(semantic_similarities, pdf5.lemmatized_text1, pdf5.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "6cffd789-9be9-4943-a181-8d28c896c122",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.855750</td>\n",
       "      <td>0.906994</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.904886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health,...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health-...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>0.962250</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.732871</td>\n",
       "      <td>0.914216</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.917892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, said, problem, needs, corrected, space, s...</td>\n",
       "      <td>[He, said, prob, lem, needs, corrected, space,...</td>\n",
       "      <td>[say, problem, need, correct, space, shuttle, ...</td>\n",
       "      <td>[say, prob, lem, need, correct, space, shuttle...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.724942</td>\n",
       "      <td>0.792256</td>\n",
       "      <td>0.664021</td>\n",
       "      <td>0.721825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[A, representative, Phoenix-based, U-Haul, dec...</td>\n",
       "      <td>[Anthony, Citrano, representative, WhenU, decl...</td>\n",
       "      <td>[representative, phoenix-based, u-haul, declin...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.613296</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.561639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "      <td>0.739940</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.565837</td>\n",
       "      <td>0.874475</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.669659</td>\n",
       "      <td>0.771062</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.754281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[Axelrod, died, heart, failure, asleep, Los, A...</td>\n",
       "      <td>[axelrod, die, sleep, heart, failure, say, dau...</td>\n",
       "      <td>[axelrod, die, heart, failure, asleep, los, an...</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.567460</td>\n",
       "      <td>0.493651</td>\n",
       "      <td>0.518707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Saddam, 's, son, Odai, surrendered, Friday, A...</td>\n",
       "      <td>[Hussein, 's, son, Uday, surrendered, yesterda...</td>\n",
       "      <td>[saddam, 's, son, odai, surrender, friday, ame...</td>\n",
       "      <td>[hussein, 's, son, uday, surrender, yesterday,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.848856</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.847222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1</td>\n",
       "      <td>[If, Senator, Clinton, decide, run, 2008, anno...</td>\n",
       "      <td>[If, Mrs, Clinton, decide, contest, 2008, elec...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, announce...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "      <td>0.800641</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.739053</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.834569</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.809704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Iranian, refugee, sewed, eyes, lips, ear...</td>\n",
       "      <td>[An, Iranian, Kurd, stitched, eyes, lips, ears...</td>\n",
       "      <td>[iranian, refugee, sew, eye, lip, ear, protest...</td>\n",
       "      <td>[iranian, kurd, stitch, eye, lip, ear, protest...</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.481812</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.567504</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.631617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Gemstar, 's, shares, gathered, 2.6, percent, ...</td>\n",
       "      <td>[Gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, 's, share, gather, 2.6, percent, add...</td>\n",
       "      <td>[gemstar, share, move, higher, news, close, 2....</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.433392</td>\n",
       "      <td>0.953463</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.555321</td>\n",
       "      <td>0.483069</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.454762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4077 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...               1   \n",
       "1     The woman was exposed to the SARS virus while ...               1   \n",
       "2     He said the prob lem needs to be corrected bef...               1   \n",
       "3     Anthony Citrano , a representative for WhenU ,...               0   \n",
       "4     The biggest threat to order seemed to be looti...               1   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...               1   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...               1   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...               1   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...               1   \n",
       "4076  Gemstar shares moved higher on the news , clos...               1   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, problem, needs, corrected, space, s...   \n",
       "3     [A, representative, Phoenix-based, U-Haul, dec...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [Saddam, 's, son, Odai, surrendered, Friday, A...   \n",
       "4074  [If, Senator, Clinton, decide, run, 2008, anno...   \n",
       "4075  [The, Iranian, refugee, sewed, eyes, lips, ear...   \n",
       "4076  [Gemstar, 's, shares, gathered, 2.6, percent, ...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, prob, lem, needs, corrected, space,...   \n",
       "3     [Anthony, Citrano, representative, WhenU, decl...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, heart, failure, asleep, Los, A...   \n",
       "4073  [Hussein, 's, son, Uday, surrendered, yesterda...   \n",
       "4074  [If, Mrs, Clinton, decide, contest, 2008, elec...   \n",
       "4075  [An, Iranian, Kurd, stitched, eyes, lips, ears...   \n",
       "4076  [Gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, begin, announce,...   \n",
       "1     [woman, expose, sars, virus, hospital, health,...   \n",
       "2     [say, problem, need, correct, space, shuttle, ...   \n",
       "3     [representative, phoenix-based, u-haul, declin...   \n",
       "4     [big, threat, order, seem, loot, crime, includ...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, die, sleep, heart, failure, say, dau...   \n",
       "4073  [saddam, 's, son, odai, surrender, friday, ame...   \n",
       "4074  [senator, clinton, decide, run, 2008, announce...   \n",
       "4075  [iranian, refugee, sew, eye, lip, ear, protest...   \n",
       "4076  [gemstar, 's, share, gather, 2.6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "0     [democratic, candidate, also, begin, announce,...   \n",
       "1     [woman, expose, sars, virus, hospital, health-...   \n",
       "2     [say, prob, lem, need, correct, space, shuttle...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [big, threat, order, seem, loot, crime, includ...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, die, heart, failure, asleep, los, an...   \n",
       "4073  [hussein, 's, son, uday, surrender, yesterday,...   \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...   \n",
       "4075  [iranian, kurd, stitch, eye, lip, ear, protest...   \n",
       "4076  [gemstar, share, move, higher, news, close, 2....   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                    0.882353           1.000000       0.000000   \n",
       "1                    0.721688           0.900000       0.077778   \n",
       "2                    0.700000           1.000000       0.000000   \n",
       "3                    0.455842           0.636364       0.207792   \n",
       "4                    0.739940           0.764706       0.199095   \n",
       "...                       ...                ...            ...   \n",
       "4072                 0.805823           0.750000       0.222222   \n",
       "4073                 0.714286           1.000000       0.000000   \n",
       "4074                 0.800641           0.923077       0.064103   \n",
       "4075                 0.518875           0.928571       0.038462   \n",
       "4076                 0.476731           0.909091       0.045455   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0           0.441176             0.882353                  1.000000   \n",
       "1           0.368421             0.649519                  0.962250   \n",
       "2           0.350000             0.700000                  1.000000   \n",
       "3           0.222222             0.290081                  0.797724   \n",
       "4           0.366667             0.565837                  0.874475   \n",
       "...              ...                  ...                       ...   \n",
       "4072        0.380952             0.604367                  0.886405   \n",
       "4073        0.333333             0.714286                  1.000000   \n",
       "4074        0.400000             0.739053                  0.960769   \n",
       "4075        0.259259             0.481812                  0.963624   \n",
       "4076        0.238095             0.433392                  0.953463   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "0                     0.789474             0.777778           0.855750   \n",
       "1                     0.636364             0.600000           0.732871   \n",
       "2                     0.538462             0.636364           0.724942   \n",
       "3                     0.285714             0.307692           0.463710   \n",
       "4                     0.578947             0.555556           0.669659   \n",
       "...                        ...                  ...                ...   \n",
       "4072                  0.583333             0.583333           0.684357   \n",
       "4073                  0.466667             0.466667           0.644444   \n",
       "4074                  0.666667             0.642857           0.756764   \n",
       "4075                  0.350000             0.388889           0.567504   \n",
       "4076                  0.312500             0.400000           0.555321   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "0                             0.906994                         0.902778   \n",
       "1                             0.914216                         0.921569   \n",
       "2                             0.792256                         0.664021   \n",
       "3                             0.613296                         0.523529   \n",
       "4                             0.771062                         0.737500   \n",
       "...                                ...                              ...   \n",
       "4072                          0.567460                         0.493651   \n",
       "4073                          0.848856                         0.847222   \n",
       "4074                          0.834569                         0.789855   \n",
       "4075                          0.700889                         0.562857   \n",
       "4076                          0.483069                         0.434921   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "0                                 0.904886  \n",
       "1                                 0.917892  \n",
       "2                                 0.721825  \n",
       "3                                 0.561639  \n",
       "4                                 0.754281  \n",
       "...                                    ...  \n",
       "4072                              0.518707  \n",
       "4073                              0.847222  \n",
       "4074                              0.809704  \n",
       "4075                              0.631617  \n",
       "4076                              0.454762  \n",
       "\n",
       "[4077 rows x 20 columns]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df2 = pdf1.append(pdf2).append(pdf3).append(pdf4).append(pdf5)\n",
    "train_df2[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']] = pd.DataFrame(train_df2.scores.tolist(), index= train_df2.index)\n",
    "train_df2.drop(['scores'], axis=1, inplace=True)\n",
    "train_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d358a1-5b4a-4ee0-b7b1-63befa044bf9",
   "metadata": {},
   "source": [
    "## 50-50 Randomly Removing Majority Class Training Dataset with Other Preprocessing Method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "03f3fbdd-dffb-4661-84ad-df2e230a2a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset0_2 = train_df2.loc[train_df2['classification'] == 0]\n",
    "subset1_2 = train_df2.loc[train_df2['classification'] == 1]\n",
    "subset1Sample_2 = subset1_2.sample(n=1039,random_state=42)\n",
    "new_train_df_2 = subset0_2.append(subset1Sample_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9997822-42a8-4a44-9cac-ac5a204cf43e",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset with Other Preprocessing Method, Outliers Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "c0fbf885-c93b-4b5b-b6f7-bc71227bf831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset0_clean_2 = remove_outliers(subset0_2, 'cosine_similarity_score', .05,.95)\n",
    "# #subset0_clean_2 = remove_outliers(subset0_clean_2, 'length_similarity', .05,.95)\n",
    "subset0_clean_2 = remove_outliers(subset0_2, 'overlap_score', .00,.90)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2, 'overlap2_score', .05,.95)\n",
    "subset0_clean_2 = remove_outliers(subset0_clean_2, 'cosine/length_ratio', .00,.90)\n",
    "# #subset0_clean_2 = remove_outliers(subset0_clean_2, 'cosine_similarity_score2', .05,.95)\n",
    "subset0_clean_2 = remove_outliers(subset0_clean_2, 'jaccard_similarity_score', .00,.90)\n",
    "subset0_clean_2 = remove_outliers(subset0_clean_2, 'lemma_jaccard_score', .00,.90)\n",
    "subset0_clean_2 = remove_outliers(subset0_clean_2, 'overall_sim_score', .00,.90)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'bigram_similarity',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'jaccard_distance_trigrams',.05,.95)\n",
    "subset0_clean_2 = remove_outliers(subset0_clean_2,'cosine_similarity_trigrams', .00,.90)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'trigram_similarity',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset0_clean_2 = remove_outliers(subset0_clean_2,'quadgram_similarity',.05,.95)\n",
    "len(subset0_clean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "ef6e2a50-d57c-4772-8b4a-0dc7041d44de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset1_clean_2 = remove_outliers(subset1_2, 'cosine_similarity_score', .05,.95)\n",
    "# #subset1_clean_2 = remove_outliers(subset1_clean_2, 'length_similarity', .05,.95)\n",
    "subset1_clean_2 = remove_outliers(subset1_2, 'overlap_score', .10,1.0)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2, 'overlap2_score', .05,.95)\n",
    "subset1_clean_2 = remove_outliers(subset1_clean_2, 'cosine/length_ratio', .10,1.0)\n",
    "# #subset1_clean_2 = remove_outliers(subset1_clean_2, 'cosine_similarity_score2', .05,.95)\n",
    "subset1_clean_2 = remove_outliers(subset1_clean_2, 'jaccard_similarity_score', .10,1.0)\n",
    "subset1_clean_2 = remove_outliers(subset1_clean_2, 'lemma_jaccard_score', .10,1.0)\n",
    "subset1_clean_2 = remove_outliers(subset1_clean_2, 'overall_sim_score', .10,1.0)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'bigram_similarity',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'jaccard_distance_trigrams',.05,.95)\n",
    "subset1_clean_2 = remove_outliers(subset1_clean_2,'cosine_similarity_trigrams',.10,1.0)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'trigram_similarity',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset1_clean_2 = remove_outliers(subset1_clean_2,'quadgram_similarity',.05,.95)\n",
    "len(subset1_clean_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "ed9a6ce7-35a7-4ea1-bf83-9b88ce57ae2a",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.590351</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.812030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.481292</td>\n",
       "      <td>0.284605</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.457632</td>\n",
       "      <td>0.274986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.726184</td>\n",
       "      <td>0.240192</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>1</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.854779</td>\n",
       "      <td>0.876714</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.739053</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2269 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.307692           0.463710   \n",
       "7                  0             0.312500           0.514166   \n",
       "8                  0             0.421053           0.590351   \n",
       "11                 0             0.307692           0.481292   \n",
       "17                 0             0.315789           0.457632   \n",
       "...              ...                  ...                ...   \n",
       "4062               1             0.611111           0.736979   \n",
       "4063               1             0.812500           0.854779   \n",
       "4072               1             0.583333           0.684357   \n",
       "4073               1             0.466667           0.644444   \n",
       "4074               1             0.642857           0.756764   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.158114   \n",
       "7                0.404796                    0.119523   \n",
       "8                0.442105                    0.226134   \n",
       "11               0.284605                    0.154303   \n",
       "17               0.274986                    0.000000   \n",
       "...                   ...                         ...   \n",
       "4062             0.726184                    0.240192   \n",
       "4063             0.876714                    0.692308   \n",
       "4072             0.604367                    0.239046   \n",
       "4073             0.714286                    0.200000   \n",
       "4074             0.739053                    0.421637   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.352941       0.861538  \n",
       "8                     0.450000       0.812030  \n",
       "11                    0.187500       0.966667  \n",
       "17                    0.350000       0.688889  \n",
       "...                        ...            ...  \n",
       "4062                  0.631579       0.950000  \n",
       "4063                  0.812500       1.000000  \n",
       "4072                  0.583333       0.777778  \n",
       "4073                  0.466667       1.000000  \n",
       "4074                  0.666667       0.935897  \n",
       "\n",
       "[2269 rows x 7 columns]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df_clean_2 = subset0_clean_2.append(subset1_clean_2)\n",
    "new_train_df_clean_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9402484e-9729-467e-8fa0-cda4101403f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a98e9bd-ad4b-4395-bdfe-681053cacde3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2f1ee27f-1bec-453d-b50c-18262fcd376b",
   "metadata": {},
   "source": [
    "## Preprocessing of Missing Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "0a550931-f98b-4297-b8f4-3b408e09bae7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3491</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3492</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3493 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "3488  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "3489  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "3490  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "3491  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "3492  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \n",
       "0     The Democratic candidates also began announcin...             1.0  \n",
       "1     The woman was exposed to the SARS virus while ...             1.0  \n",
       "2     He said the prob lem needs to be corrected bef...             1.0  \n",
       "3     Anthony Citrano , a representative for WhenU ,...             0.0  \n",
       "4     The biggest threat to order seemed to be looti...             1.0  \n",
       "...                                                 ...             ...  \n",
       "3488  Axelrod died of heart failure while asleep at ...             1.0  \n",
       "3489  Hussein 's other son , Uday , surrendered yest...             1.0  \n",
       "3490  If Mrs Clinton does decide to contest the 2008...             1.0  \n",
       "3491  An Iranian Kurd who stitched up his eyes , lip...             1.0  \n",
       "3492  Gemstar shares moved higher on the news , clos...             1.0  \n",
       "\n",
       "[3493 rows x 4 columns]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_train = pd.read_csv(\"../Data/train_with_label.txt\", error_bad_lines = False, warn_bad_lines = False, engine = 'python', header = None, sep='\\t', )\n",
    "missing_train = missing_train.rename(columns={0: \"id\", 1: \"sentence1\", 2: \"sentence2\", 3: \"classification\"})\n",
    "missing_train[\"classification\"] = pd.to_numeric(missing_train[\"classification\"])\n",
    "missing_train.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "b295b37c-2934-4196-9e89-4e6fc0fdb9a0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>train_id_8</td>\n",
       "      <td>\" We see the First Amendment to protect religi...</td>\n",
       "      <td>\" We put the call out , \" said the Rev. Patric...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[see, first, amendment, protect, religious, li...</td>\n",
       "      <td>[see, first, amendment, protect, religious, li...</td>\n",
       "      <td>[put, call, said, rev, patrick, j, mahoney, di...</td>\n",
       "      <td>[put, call, said, rev, patrick, j, mahoney, di...</td>\n",
       "      <td>0.471940</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.198864</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.876460</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.551413</td>\n",
       "      <td>0.736895</td>\n",
       "      <td>0.584127</td>\n",
       "      <td>0.653810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>train_id_16</td>\n",
       "      <td>\" Due to economic and creative realities , man...</td>\n",
       "      <td>\" Due to economic and creative realities , man...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[due, economic, creative, realities, many, key...</td>\n",
       "      <td>[due, economic, creative, reality, many, key, ...</td>\n",
       "      <td>[due, economic, creative, realities, many, key...</td>\n",
       "      <td>[due, economic, creative, reality, many, key, ...</td>\n",
       "      <td>0.741249</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.054945</td>\n",
       "      <td>0.370370</td>\n",
       "      <td>0.688303</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.713365</td>\n",
       "      <td>0.696502</td>\n",
       "      <td>0.622399</td>\n",
       "      <td>0.651733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>train_id_19</td>\n",
       "      <td>\" Tomorrow at the Mission Inn , I have the opp...</td>\n",
       "      <td>\" I have the opportunity to congratulate the g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[tomorrow, mission, inn, opportunity, congratu...</td>\n",
       "      <td>[tomorrow, mission, inn, opportunity, congratu...</td>\n",
       "      <td>[opportunity, congratulate, governor, elect, g...</td>\n",
       "      <td>[opportunity, congratulate, governor, elect, g...</td>\n",
       "      <td>0.737865</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.664078</td>\n",
       "      <td>0.948683</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.705117</td>\n",
       "      <td>0.907483</td>\n",
       "      <td>0.729825</td>\n",
       "      <td>0.818654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>train_id_34</td>\n",
       "      <td>\" These despicable acts were committed by kill...</td>\n",
       "      <td>These despicable acts were committed by killer...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[despicable, acts, committed, killers, whose, ...</td>\n",
       "      <td>[despicable, act, committed, killer, whose, fa...</td>\n",
       "      <td>[despicable, acts, committed, killers, whose, ...</td>\n",
       "      <td>[despicable, act, committed, killer, whose, fa...</td>\n",
       "      <td>0.788241</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.052381</td>\n",
       "      <td>0.379310</td>\n",
       "      <td>0.735691</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.715538</td>\n",
       "      <td>0.778325</td>\n",
       "      <td>0.764368</td>\n",
       "      <td>0.769622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>train_id_35</td>\n",
       "      <td>\" It is about a third of what I owe in the wor...</td>\n",
       "      <td>It ain 't coming to me , but it 's only about ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[third, owe, world, told, reporters]</td>\n",
       "      <td>[third, owe, world, told, reporter]</td>\n",
       "      <td>[coming, third, owe, world]</td>\n",
       "      <td>[coming, third, owe, world]</td>\n",
       "      <td>0.670820</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.536656</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.631476</td>\n",
       "      <td>0.651852</td>\n",
       "      <td>0.519136</td>\n",
       "      <td>0.581397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4018</th>\n",
       "      <td>train_id_4018</td>\n",
       "      <td>\" We put a lot of effort and energy into impro...</td>\n",
       "      <td>\" We 've put a lot of effort and energy into i...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[put, lot, effort, energy, improving, patching...</td>\n",
       "      <td>[put, lot, effort, energy, improving, patching...</td>\n",
       "      <td>[put, lot, effort, energy, improving, patching...</td>\n",
       "      <td>[put, lot, effort, energy, improving, patching...</td>\n",
       "      <td>0.769800</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.698932</td>\n",
       "      <td>0.959064</td>\n",
       "      <td>0.853175</td>\n",
       "      <td>0.905458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4022</th>\n",
       "      <td>train_id_4022</td>\n",
       "      <td>\" At this point , Mr. Brando announced : ' Som...</td>\n",
       "      <td>Brando said that \" somebody ought to put a bul...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[point, mr, brando, announced, somebody, ought...</td>\n",
       "      <td>[point, mr, brando, announced, somebody, ought...</td>\n",
       "      <td>[brando, said, somebody, ought, put, bullet, h...</td>\n",
       "      <td>[brando, said, somebody, ought, put, bullet, h...</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.493382</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.587226</td>\n",
       "      <td>0.578291</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.561429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4033</th>\n",
       "      <td>train_id_4033</td>\n",
       "      <td>\" Saddam is gone , but we want the ( U.S. ) oc...</td>\n",
       "      <td>\" Saddam is gone , but we want the ( U.S. ) oc...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[saddam, gone, want, u, occupation, end, said,...</td>\n",
       "      <td>[saddam, gone, want, u, occupation, end, said,...</td>\n",
       "      <td>[saddam, gone, want, u, occupation, end]</td>\n",
       "      <td>[saddam, gone, want, u, occupation, end]</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.402845</td>\n",
       "      <td>0.738549</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.609819</td>\n",
       "      <td>0.927493</td>\n",
       "      <td>0.782680</td>\n",
       "      <td>0.855086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4034</th>\n",
       "      <td>train_id_4034</td>\n",
       "      <td>Dr. Anthony Fauci , director of the National I...</td>\n",
       "      <td>\" We have been somewhat lucky , \" said Dr. Ant...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[dr, anthony, fauci, director, national, insti...</td>\n",
       "      <td>[dr, anthony, fauci, director, national, insti...</td>\n",
       "      <td>[somewhat, lucky, said, dr, anthony, fauci, di...</td>\n",
       "      <td>[somewhat, lucky, said, dr, anthony, fauci, di...</td>\n",
       "      <td>0.821584</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.409091</td>\n",
       "      <td>0.684653</td>\n",
       "      <td>0.912871</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.765829</td>\n",
       "      <td>0.607792</td>\n",
       "      <td>0.571212</td>\n",
       "      <td>0.587987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4054</th>\n",
       "      <td>train_id_4054</td>\n",
       "      <td>\" Approximately 60 per cent of all national ad...</td>\n",
       "      <td>\" Approximately 60 percent of all national adv...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[approximately, 60, per, cent, national, adver...</td>\n",
       "      <td>[approximately, 60, per, cent, national, adver...</td>\n",
       "      <td>[approximately, 60, percent, national, adverti...</td>\n",
       "      <td>[approximately, 60, percent, national, adverti...</td>\n",
       "      <td>0.782624</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.626099</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.722385</td>\n",
       "      <td>0.890572</td>\n",
       "      <td>0.853704</td>\n",
       "      <td>0.871782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>584 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "8        train_id_8  \" We see the First Amendment to protect religi...   \n",
       "16      train_id_16  \" Due to economic and creative realities , man...   \n",
       "19      train_id_19  \" Tomorrow at the Mission Inn , I have the opp...   \n",
       "34      train_id_34  \" These despicable acts were committed by kill...   \n",
       "35      train_id_35  \" It is about a third of what I owe in the wor...   \n",
       "...             ...                                                ...   \n",
       "4018  train_id_4018  \" We put a lot of effort and energy into impro...   \n",
       "4022  train_id_4022  \" At this point , Mr. Brando announced : ' Som...   \n",
       "4033  train_id_4033  \" Saddam is gone , but we want the ( U.S. ) oc...   \n",
       "4034  train_id_4034  Dr. Anthony Fauci , director of the National I...   \n",
       "4054  train_id_4054  \" Approximately 60 per cent of all national ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "8     \" We put the call out , \" said the Rev. Patric...             0.0   \n",
       "16    \" Due to economic and creative realities , man...             1.0   \n",
       "19    \" I have the opportunity to congratulate the g...             0.0   \n",
       "34    These despicable acts were committed by killer...             0.0   \n",
       "35    It ain 't coming to me , but it 's only about ...             0.0   \n",
       "...                                                 ...             ...   \n",
       "4018  \" We 've put a lot of effort and energy into i...             0.0   \n",
       "4022  Brando said that \" somebody ought to put a bul...             1.0   \n",
       "4033  \" Saddam is gone , but we want the ( U.S. ) oc...             1.0   \n",
       "4034  \" We have been somewhat lucky , \" said Dr. Ant...             0.0   \n",
       "4054  \" Approximately 60 percent of all national adv...             1.0   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "8     [see, first, amendment, protect, religious, li...   \n",
       "16    [due, economic, creative, realities, many, key...   \n",
       "19    [tomorrow, mission, inn, opportunity, congratu...   \n",
       "34    [despicable, acts, committed, killers, whose, ...   \n",
       "35                 [third, owe, world, told, reporters]   \n",
       "...                                                 ...   \n",
       "4018  [put, lot, effort, energy, improving, patching...   \n",
       "4022  [point, mr, brando, announced, somebody, ought...   \n",
       "4033  [saddam, gone, want, u, occupation, end, said,...   \n",
       "4034  [dr, anthony, fauci, director, national, insti...   \n",
       "4054  [approximately, 60, per, cent, national, adver...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "8     [see, first, amendment, protect, religious, li...   \n",
       "16    [due, economic, creative, reality, many, key, ...   \n",
       "19    [tomorrow, mission, inn, opportunity, congratu...   \n",
       "34    [despicable, act, committed, killer, whose, fa...   \n",
       "35                  [third, owe, world, told, reporter]   \n",
       "...                                                 ...   \n",
       "4018  [put, lot, effort, energy, improving, patching...   \n",
       "4022  [point, mr, brando, announced, somebody, ought...   \n",
       "4033  [saddam, gone, want, u, occupation, end, said,...   \n",
       "4034  [dr, anthony, fauci, director, national, insti...   \n",
       "4054  [approximately, 60, per, cent, national, adver...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "8     [put, call, said, rev, patrick, j, mahoney, di...   \n",
       "16    [due, economic, creative, realities, many, key...   \n",
       "19    [opportunity, congratulate, governor, elect, g...   \n",
       "34    [despicable, acts, committed, killers, whose, ...   \n",
       "35                          [coming, third, owe, world]   \n",
       "...                                                 ...   \n",
       "4018  [put, lot, effort, energy, improving, patching...   \n",
       "4022  [brando, said, somebody, ought, put, bullet, h...   \n",
       "4033           [saddam, gone, want, u, occupation, end]   \n",
       "4034  [somewhat, lucky, said, dr, anthony, fauci, di...   \n",
       "4054  [approximately, 60, percent, national, adverti...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "8     [put, call, said, rev, patrick, j, mahoney, di...   \n",
       "16    [due, economic, creative, reality, many, key, ...   \n",
       "19    [opportunity, congratulate, governor, elect, g...   \n",
       "34    [despicable, act, committed, killer, whose, fa...   \n",
       "35                          [coming, third, owe, world]   \n",
       "...                                                 ...   \n",
       "4018  [put, lot, effort, energy, improving, patching...   \n",
       "4022  [brando, said, somebody, ought, put, bullet, h...   \n",
       "4033           [saddam, gone, want, u, occupation, end]   \n",
       "4034  [somewhat, lucky, said, dr, anthony, fauci, di...   \n",
       "4054  [approximately, 60, percent, national, adverti...   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "8                    0.471940           0.687500       0.198864   \n",
       "16                   0.741249           0.928571       0.054945   \n",
       "19                   0.737865           0.900000       0.077778   \n",
       "34                   0.788241           0.933333       0.052381   \n",
       "35                   0.670820           0.800000       0.150000   \n",
       "...                       ...                ...            ...   \n",
       "4018                 0.769800           0.750000       0.222222   \n",
       "4022                 0.603023           0.818182       0.121212   \n",
       "4033                 0.738549           0.545455       0.454545   \n",
       "4034                 0.821584           0.833333       0.150000   \n",
       "4054                 0.782624           0.800000       0.175000   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "8           0.259259             0.324459                  0.876460   \n",
       "16          0.370370             0.688303                  0.963624   \n",
       "19          0.368421             0.664078                  0.948683   \n",
       "34          0.379310             0.735691                  0.970143   \n",
       "35          0.333333             0.536656                  0.894427   \n",
       "...              ...                  ...                       ...   \n",
       "4018        0.380952             0.577350                  0.866025   \n",
       "4022        0.300000             0.493382                  0.904534   \n",
       "4033        0.352941             0.402845                  0.738549   \n",
       "4034        0.409091             0.684653                  0.912871   \n",
       "4054        0.388889             0.626099                  0.894427   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "8                     0.388889             0.388889           0.551413   \n",
       "16                    0.588235             0.588235           0.713365   \n",
       "19                    0.583333             0.583333           0.705117   \n",
       "34                    0.588235             0.588235           0.715538   \n",
       "35                    0.500000             0.500000           0.631476   \n",
       "...                        ...                  ...                ...   \n",
       "4018                  0.615385             0.615385           0.698932   \n",
       "4022                  0.428571             0.428571           0.587226   \n",
       "4033                  0.545455             0.545455           0.609819   \n",
       "4034                  0.692308             0.692308           0.765829   \n",
       "4054                  0.636364             0.636364           0.722385   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "8                             0.736895                         0.584127   \n",
       "16                            0.696502                         0.622399   \n",
       "19                            0.907483                         0.729825   \n",
       "34                            0.778325                         0.764368   \n",
       "35                            0.651852                         0.519136   \n",
       "...                                ...                              ...   \n",
       "4018                          0.959064                         0.853175   \n",
       "4022                          0.578291                         0.556667   \n",
       "4033                          0.927493                         0.782680   \n",
       "4034                          0.607792                         0.571212   \n",
       "4054                          0.890572                         0.853704   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "8                                 0.653810  \n",
       "16                                0.651733  \n",
       "19                                0.818654  \n",
       "34                                0.769622  \n",
       "35                                0.581397  \n",
       "...                                    ...  \n",
       "4018                              0.905458  \n",
       "4022                              0.561429  \n",
       "4033                              0.855086  \n",
       "4034                              0.587987  \n",
       "4054                              0.871782  \n",
       "\n",
       "[584 rows x 20 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing = pd.concat([train_df,missing_train]).drop_duplicates(subset = ['id','id'], keep=False)\n",
    "missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2dac3e68-6ee6-4ada-98cc-fe168733385d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.055147</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.856008</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878936</td>\n",
       "      <td>0.919913</td>\n",
       "      <td>0.915825</td>\n",
       "      <td>0.917869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>0.954786</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.943262</td>\n",
       "      <td>0.870098</td>\n",
       "      <td>0.877451</td>\n",
       "      <td>0.873775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[said, problem, needs, corrected, space, shutt...</td>\n",
       "      <td>[said, problem, need, corrected, space, shuttl...</td>\n",
       "      <td>[said, prob, lem, needs, corrected, space, shu...</td>\n",
       "      <td>[said, prob, lem, need, corrected, space, shut...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.712121</td>\n",
       "      <td>0.825926</td>\n",
       "      <td>0.741799</td>\n",
       "      <td>0.780159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.541266</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.659046</td>\n",
       "      <td>0.818681</td>\n",
       "      <td>0.794643</td>\n",
       "      <td>0.806662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.534127</td>\n",
       "      <td>0.485714</td>\n",
       "      <td>0.504819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[mrs, clinton, decide, contest, 2008, election...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "      <td>0.819892</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.799178</td>\n",
       "      <td>0.791613</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.758261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[iranian, refugee, sewed, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, refugee, sewed, eye, lip, ear, prote...</td>\n",
       "      <td>[iranian, kurd, stitched, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, kurd, stitched, eye, lip, ear, prote...</td>\n",
       "      <td>0.560449</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.517337</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.579516</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.631617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[gemstar, shares, gathered, 2, 6, percent, add...</td>\n",
       "      <td>[gemstar, share, gathered, 2, 6, percent, addi...</td>\n",
       "      <td>[gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, share, moved, higher, news, closing,...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.607843</td>\n",
       "      <td>0.687302</td>\n",
       "      <td>0.592460</td>\n",
       "      <td>0.631049</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3493 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...             1.0   \n",
       "1     The woman was exposed to the SARS virus while ...             1.0   \n",
       "2     He said the prob lem needs to be corrected bef...             1.0   \n",
       "3     Anthony Citrano , a representative for WhenU ,...             0.0   \n",
       "4     The biggest threat to order seemed to be looti...             1.0   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...             1.0   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...             1.0   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...             1.0   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...             1.0   \n",
       "4076  Gemstar shares moved higher on the news , clos...             1.0   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, needs, corrected, space, shutt...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, gathered, 2, 6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, need, corrected, space, shuttl...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, gathered, 2, 6, percent, addi...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, needs, corrected, space, shu...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mrs, clinton, decide, contest, 2008, election...   \n",
       "4075  [iranian, kurd, stitched, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, need, corrected, space, shut...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...   \n",
       "4075  [iranian, kurd, stitched, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, moved, higher, news, closing,...   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                    0.909509           0.941176       0.055147   \n",
       "1                    0.904534           0.888889       0.111111   \n",
       "2                    0.666667           1.000000       0.000000   \n",
       "3                    0.455842           0.636364       0.207792   \n",
       "4                    0.721688           0.750000       0.208333   \n",
       "...                       ...                ...            ...   \n",
       "4072                 0.805823           0.750000       0.222222   \n",
       "4073                 0.600000           1.000000       0.000000   \n",
       "4074                 0.819892           0.923077       0.064103   \n",
       "4075                 0.560449           0.923077       0.044872   \n",
       "4076                 0.583333           1.000000       0.000000   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0           0.454545             0.856008                  0.970143   \n",
       "1           0.470588             0.804030                  0.954786   \n",
       "2           0.333333             0.666667                  1.000000   \n",
       "3           0.222222             0.290081                  0.797724   \n",
       "4           0.357143             0.541266                  0.866025   \n",
       "...              ...                  ...                       ...   \n",
       "4072        0.380952             0.604367                  0.886405   \n",
       "4073        0.300000             0.600000                  1.000000   \n",
       "4074        0.400000             0.756823                  0.968963   \n",
       "4075        0.280000             0.517337                  0.960769   \n",
       "4076        0.291667             0.583333                  1.000000   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "0                     0.833333             0.833333           0.878936   \n",
       "1                     0.937500             0.937500           0.943262   \n",
       "2                     0.500000             0.636364           0.712121   \n",
       "3                     0.285714             0.285714           0.456384   \n",
       "4                     0.555556             0.555556           0.659046   \n",
       "...                        ...                  ...                ...   \n",
       "4072                  0.583333             0.583333           0.684357   \n",
       "4073                  0.428571             0.538462           0.655678   \n",
       "4074                  0.714286             0.714286           0.799178   \n",
       "4075                  0.388889             0.388889           0.579516   \n",
       "4076                  0.411765             0.411765           0.607843   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "0                             0.919913                         0.915825   \n",
       "1                             0.870098                         0.877451   \n",
       "2                             0.825926                         0.741799   \n",
       "3                             0.681597                         0.526984   \n",
       "4                             0.818681                         0.794643   \n",
       "...                                ...                              ...   \n",
       "4072                          0.534127                         0.485714   \n",
       "4073                          0.883333                         0.883333   \n",
       "4074                          0.791613                         0.740000   \n",
       "4075                          0.700889                         0.562857   \n",
       "4076                          0.687302                         0.592460   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "0                                 0.917869  \n",
       "1                                 0.873775  \n",
       "2                                 0.780159  \n",
       "3                                 0.577681  \n",
       "4                                 0.806662  \n",
       "...                                    ...  \n",
       "4072                              0.504819  \n",
       "4073                              0.883333  \n",
       "4074                              0.758261  \n",
       "4075                              0.631617  \n",
       "4076                              0.631049  \n",
       "\n",
       "[3493 rows x 20 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We now let missing_train equal the difference between train_df and missing so that we do not need to repeat all the preprocessing:\n",
    "missing_train = pd.concat([train_df,missing]).drop_duplicates(subset = ['id','id'], keep=False)\n",
    "missing_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c11f8aa-776e-49f5-958a-9833183ea9d6",
   "metadata": {},
   "source": [
    "## Preprocessing of Missing Training Dataset with Outliers Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "a91490dd-6ed1-46a0-9a1e-f6833b6f47bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset0Missing = missing_train.loc[missing_train['classification'] == 0]\n",
    "subset1Missing = missing_train.loc[missing_train['classification'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "68fce988-9dcf-4fbf-8947-ad4a5635fa71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "562"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset0_clean_Missing = remove_outliers(subset0Missing, 'cosine_similarity_score', .05,.95)\n",
    "# #subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'length_similarity', .05,.95)\n",
    "subset0_clean_Missing = remove_outliers(subset0Missing, 'overlap_score', .00,.90)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'overlap2_score', .05,.95)\n",
    "subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'cosine/length_ratio', .00,.90)\n",
    "# #subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'cosine_similarity_score2', .05,.95)\n",
    "subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'jaccard_similarity_score', .00,.90)\n",
    "subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'lemma_jaccard_score', .00,.90)\n",
    "subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'overall_sim_score', .00,.90)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'bigram_similarity',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'jaccard_distance_trigrams',.05,.95)\n",
    "subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'cosine_similarity_trigrams', .00,.90)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'trigram_similarity',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset0_clean_Missing = remove_outliers(subset0_clean_Missing,'quadgram_similarity',.05,.95)\n",
    "len(subset0_clean_Missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "44719325-0b76-4f04-8645-e0267f11193b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1392"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset1_clean_Missing = remove_outliers(subset1Missing, 'cosine_similarity_score', .05,.95)\n",
    "# #subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'length_similarity', .05,.95)\n",
    "subset1_clean_Missing = remove_outliers(subset1Missing, 'overlap_score', .10,1.0)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'overlap2_score', .05,.95)\n",
    "subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'cosine/length_ratio', .10,1.0)\n",
    "# #subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'cosine_similarity_score2', .05,.95)\n",
    "subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'jaccard_similarity_score', .10,1.0)\n",
    "subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'lemma_jaccard_score', .10,1.0)\n",
    "subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'overall_sim_score', .10,1.0)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'bigram_similarity',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'jaccard_distance_trigrams',.05,.95)\n",
    "subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'cosine_similarity_trigrams',.10,1.0)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'trigram_similarity',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset1_clean_Missing = remove_outliers(subset1_clean_Missing,'quadgram_similarity',.05,.95)\n",
    "len(subset1_clean_Missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "77474520-7fb0-4f49-8857-1eeadeb84926",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.513111</td>\n",
       "      <td>0.341096</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.631818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3479</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.870857</td>\n",
       "      <td>0.890264</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3480</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.643223</td>\n",
       "      <td>0.493007</td>\n",
       "      <td>0.335410</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.883333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3488</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3489</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.655678</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3490</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.799178</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1954 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                0.0             0.285714           0.456384   \n",
       "7                0.0             0.411765           0.530084   \n",
       "10               0.0             0.200000           0.431476   \n",
       "15               0.0             0.380952           0.472186   \n",
       "19               0.0             0.428571           0.513111   \n",
       "...              ...                  ...                ...   \n",
       "3479             1.0             0.833333           0.870857   \n",
       "3480             1.0             0.500000           0.643223   \n",
       "3488             1.0             0.583333           0.684357   \n",
       "3489             1.0             0.538462           0.655678   \n",
       "3490             1.0             0.714286           0.799178   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.149071   \n",
       "7                0.362209                    0.204124   \n",
       "10               0.268328                    0.000000   \n",
       "15               0.360060                    0.000000   \n",
       "19               0.341096                    0.314270   \n",
       "...                   ...                         ...   \n",
       "3479             0.890264                    0.733333   \n",
       "3480             0.493007                    0.335410   \n",
       "3488             0.604367                    0.239046   \n",
       "3489             0.600000                    0.375000   \n",
       "3490             0.756823                    0.476731   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.333333       0.828571  \n",
       "10                    0.200000       0.925000  \n",
       "15                    0.380952       0.700000  \n",
       "19                    0.428571       0.631818  \n",
       "...                        ...            ...  \n",
       "3479                  0.833333       1.000000  \n",
       "3480                  0.500000       0.883333  \n",
       "3488                  0.583333       0.777778  \n",
       "3489                  0.428571       1.000000  \n",
       "3490                  0.714286       0.935897  \n",
       "\n",
       "[1954 rows x 7 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df_clean_Missing = subset0_clean_Missing.append(subset1_clean_Missing)\n",
    "new_train_df_clean_Missing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a498c9e3-7c9b-4f42-a7e0-2129e91cb339",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class for Missing Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3059ec1f-644c-4857-8327-37f63317bc9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    0.74091\n",
       "0.0    0.25909\n",
       "Name: classification, dtype: float64"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_train['classification'].value_counts()/missing_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e5d89d4a-a032-41ae-95fe-d18309f38fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "905\n",
      "2588\n"
     ]
    }
   ],
   "source": [
    "print(len(subset0Missing))\n",
    "print(len(subset1Missing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "8b3c9aea-1565-453c-864b-4c6a349fc25b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.681597</td>\n",
       "      <td>0.526984</td>\n",
       "      <td>0.577681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>train_id_5</td>\n",
       "      <td>Crews worked to install a new culvert and prep...</td>\n",
       "      <td>Crews worked to install a new culvert and repa...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[crews, worked, install, new, culvert, prepare...</td>\n",
       "      <td>[crew, worked, install, new, culvert, prepare,...</td>\n",
       "      <td>[crews, worked, install, new, culvert, repave,...</td>\n",
       "      <td>[crew, worked, install, new, culvert, repave, ...</td>\n",
       "      <td>0.784465</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.566558</td>\n",
       "      <td>0.849837</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.704331</td>\n",
       "      <td>0.880645</td>\n",
       "      <td>0.860215</td>\n",
       "      <td>0.870430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>train_id_7</td>\n",
       "      <td>It will cost about $ 20,000 per eight-week cou...</td>\n",
       "      <td>It will cost about $ 20,000 per average course...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[cost, 20, 000, per, eight, week, course, trea...</td>\n",
       "      <td>[cost, 20, 000, per, eight, week, course, trea...</td>\n",
       "      <td>[cost, 20, 000, per, average, course, treatmen...</td>\n",
       "      <td>[cost, 20, 000, per, average, course, treatmen...</td>\n",
       "      <td>0.507093</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>0.845154</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.706279</td>\n",
       "      <td>0.581481</td>\n",
       "      <td>0.637763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>train_id_11</td>\n",
       "      <td>A federal judge ruled that the monument violat...</td>\n",
       "      <td>The federal courts have ruled that the monumen...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[federal, judge, ruled, monument, violated, la...</td>\n",
       "      <td>[federal, judge, ruled, monument, violated, la...</td>\n",
       "      <td>[federal, courts, ruled, monument, violates, c...</td>\n",
       "      <td>[federal, court, ruled, monument, violates, co...</td>\n",
       "      <td>0.335410</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0.894427</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.475926</td>\n",
       "      <td>0.537963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>train_id_17</td>\n",
       "      <td>The benchmark 10-year note US10YT = RR slipped...</td>\n",
       "      <td>The yield on the 10-year Treasury note rose to...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[benchmark, 10, year, note, us10yt, rr, slippe...</td>\n",
       "      <td>[benchmark, 10, year, note, us10yt, rr, slippe...</td>\n",
       "      <td>[yield, 10, year, treasury, note, rose, 4, 46,...</td>\n",
       "      <td>[yield, 10, year, treasury, note, rose, 4, 46,...</td>\n",
       "      <td>0.600099</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.281250</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.654654</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.878325</td>\n",
       "      <td>0.732465</td>\n",
       "      <td>0.805395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3050</th>\n",
       "      <td>train_id_3050</td>\n",
       "      <td>By 10 p.m. , Claudette was centered about 320 ...</td>\n",
       "      <td>Early Monday , the center of Claudette was abo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[10, p, claudette, centered, 320, miles, east,...</td>\n",
       "      <td>[10, p, claudette, centered, 320, mile, east, ...</td>\n",
       "      <td>[early, monday, center, claudette, 300, miles,...</td>\n",
       "      <td>[early, monday, center, claudette, 300, mile, ...</td>\n",
       "      <td>0.731925</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.038012</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>0.693403</td>\n",
       "      <td>0.927105</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.590909</td>\n",
       "      <td>0.679918</td>\n",
       "      <td>0.858281</td>\n",
       "      <td>0.801351</td>\n",
       "      <td>0.829816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>train_id_98</td>\n",
       "      <td>Market sentiment was subdued after Internation...</td>\n",
       "      <td>Market sentiment was also cautious after Inter...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[market, sentiment, subdued, international, bu...</td>\n",
       "      <td>[market, sentiment, subdued, international, bu...</td>\n",
       "      <td>[market, sentiment, also, cautious, internatio...</td>\n",
       "      <td>[market, sentiment, also, cautious, internatio...</td>\n",
       "      <td>0.723339</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>0.080495</td>\n",
       "      <td>0.361111</td>\n",
       "      <td>0.647198</td>\n",
       "      <td>0.945905</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.692113</td>\n",
       "      <td>0.860529</td>\n",
       "      <td>0.773677</td>\n",
       "      <td>0.815251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>train_id_607</td>\n",
       "      <td>Clijsters was simply too complete and powerful...</td>\n",
       "      <td>Clijsters was simply too powerful for Spanish ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[clijsters, simply, complete, powerful, spanis...</td>\n",
       "      <td>[clijsters, simply, complete, powerful, spanis...</td>\n",
       "      <td>[clijsters, simply, powerful, spanish, veteran...</td>\n",
       "      <td>[clijsters, simply, powerful, spanish, veteran...</td>\n",
       "      <td>0.868599</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.130952</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.744513</td>\n",
       "      <td>0.868599</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.765723</td>\n",
       "      <td>0.837912</td>\n",
       "      <td>0.819414</td>\n",
       "      <td>0.826127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1505</th>\n",
       "      <td>train_id_1505</td>\n",
       "      <td>The companies , Chiron and Aventis Pasteur , t...</td>\n",
       "      <td>Chiron and Aventis Pasteur together made about...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[companies, chiron, aventis, pasteur, together...</td>\n",
       "      <td>[company, chiron, aventis, pasteur, together, ...</td>\n",
       "      <td>[chiron, aventis, pasteur, together, made, 80,...</td>\n",
       "      <td>[chiron, aventis, pasteur, together, made, 80,...</td>\n",
       "      <td>0.751469</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.663061</td>\n",
       "      <td>0.939336</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.713112</td>\n",
       "      <td>0.744528</td>\n",
       "      <td>0.704315</td>\n",
       "      <td>0.715877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>train_id_538</td>\n",
       "      <td>US authorities blame Al Qaeda for the attacks ...</td>\n",
       "      <td>U.S. authorities blame Osama bin Laden 's al-Q...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[us, authorities, blame, al, qaeda, attacks, k...</td>\n",
       "      <td>[u, authority, blame, al, qaeda, attack, kille...</td>\n",
       "      <td>[u, authorities, blame, osama, bin, laden, al,...</td>\n",
       "      <td>[u, authority, blame, osama, bin, laden, al, q...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.541266</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.689547</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.805952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1810 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "5        train_id_5  Crews worked to install a new culvert and prep...   \n",
       "7        train_id_7  It will cost about $ 20,000 per eight-week cou...   \n",
       "11      train_id_11  A federal judge ruled that the monument violat...   \n",
       "17      train_id_17  The benchmark 10-year note US10YT = RR slipped...   \n",
       "...             ...                                                ...   \n",
       "3050  train_id_3050  By 10 p.m. , Claudette was centered about 320 ...   \n",
       "98      train_id_98  Market sentiment was subdued after Internation...   \n",
       "607    train_id_607  Clijsters was simply too complete and powerful...   \n",
       "1505  train_id_1505  The companies , Chiron and Aventis Pasteur , t...   \n",
       "538    train_id_538  US authorities blame Al Qaeda for the attacks ...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "3     Anthony Citrano , a representative for WhenU ,...             0.0   \n",
       "5     Crews worked to install a new culvert and repa...             0.0   \n",
       "7     It will cost about $ 20,000 per average course...             0.0   \n",
       "11    The federal courts have ruled that the monumen...             0.0   \n",
       "17    The yield on the 10-year Treasury note rose to...             0.0   \n",
       "...                                                 ...             ...   \n",
       "3050  Early Monday , the center of Claudette was abo...             1.0   \n",
       "98    Market sentiment was also cautious after Inter...             1.0   \n",
       "607   Clijsters was simply too powerful for Spanish ...             1.0   \n",
       "1505  Chiron and Aventis Pasteur together made about...             1.0   \n",
       "538   U.S. authorities blame Osama bin Laden 's al-Q...             1.0   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "5     [crews, worked, install, new, culvert, prepare...   \n",
       "7     [cost, 20, 000, per, eight, week, course, trea...   \n",
       "11    [federal, judge, ruled, monument, violated, la...   \n",
       "17    [benchmark, 10, year, note, us10yt, rr, slippe...   \n",
       "...                                                 ...   \n",
       "3050  [10, p, claudette, centered, 320, miles, east,...   \n",
       "98    [market, sentiment, subdued, international, bu...   \n",
       "607   [clijsters, simply, complete, powerful, spanis...   \n",
       "1505  [companies, chiron, aventis, pasteur, together...   \n",
       "538   [us, authorities, blame, al, qaeda, attacks, k...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "5     [crew, worked, install, new, culvert, prepare,...   \n",
       "7     [cost, 20, 000, per, eight, week, course, trea...   \n",
       "11    [federal, judge, ruled, monument, violated, la...   \n",
       "17    [benchmark, 10, year, note, us10yt, rr, slippe...   \n",
       "...                                                 ...   \n",
       "3050  [10, p, claudette, centered, 320, mile, east, ...   \n",
       "98    [market, sentiment, subdued, international, bu...   \n",
       "607   [clijsters, simply, complete, powerful, spanis...   \n",
       "1505  [company, chiron, aventis, pasteur, together, ...   \n",
       "538   [u, authority, blame, al, qaeda, attack, kille...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "5     [crews, worked, install, new, culvert, repave,...   \n",
       "7     [cost, 20, 000, per, average, course, treatmen...   \n",
       "11    [federal, courts, ruled, monument, violates, c...   \n",
       "17    [yield, 10, year, treasury, note, rose, 4, 46,...   \n",
       "...                                                 ...   \n",
       "3050  [early, monday, center, claudette, 300, miles,...   \n",
       "98    [market, sentiment, also, cautious, internatio...   \n",
       "607   [clijsters, simply, powerful, spanish, veteran...   \n",
       "1505  [chiron, aventis, pasteur, together, made, 80,...   \n",
       "538   [u, authorities, blame, osama, bin, laden, al,...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "5     [crew, worked, install, new, culvert, repave, ...   \n",
       "7     [cost, 20, 000, per, average, course, treatmen...   \n",
       "11    [federal, court, ruled, monument, violates, co...   \n",
       "17    [yield, 10, year, treasury, note, rose, 4, 46,...   \n",
       "...                                                 ...   \n",
       "3050  [early, monday, center, claudette, 300, mile, ...   \n",
       "98    [market, sentiment, also, cautious, internatio...   \n",
       "607   [clijsters, simply, powerful, spanish, veteran...   \n",
       "1505  [chiron, aventis, pasteur, together, made, 80,...   \n",
       "538   [u, authority, blame, osama, bin, laden, al, q...   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "3                    0.455842           0.636364       0.207792   \n",
       "5                    0.784465           0.722222       0.256410   \n",
       "7                    0.507093           0.714286       0.171429   \n",
       "11                   0.335410           0.800000       0.075000   \n",
       "17                   0.600099           0.600000       0.300000   \n",
       "...                       ...                ...            ...   \n",
       "3050                 0.731925           0.947368       0.038012   \n",
       "98                   0.723339           0.894737       0.080495   \n",
       "607                  0.868599           0.857143       0.130952   \n",
       "1505                 0.751469           0.882353       0.094118   \n",
       "538                  0.721688           0.750000       0.208333   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "3           0.222222             0.290081                  0.797724   \n",
       "5           0.387097             0.566558                  0.849837   \n",
       "7           0.250000             0.362209                  0.845154   \n",
       "11          0.166667             0.268328                  0.894427   \n",
       "17          0.281250             0.360060                  0.654654   \n",
       "...              ...                  ...                       ...   \n",
       "3050        0.351351             0.693403                  0.927105   \n",
       "98          0.361111             0.647198                  0.945905   \n",
       "607         0.423077             0.744513                  0.868599   \n",
       "1505        0.375000             0.663061                  0.939336   \n",
       "538         0.357143             0.541266                  0.866025   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                     0.285714             0.285714           0.456384   \n",
       "5                     0.631579             0.631579           0.704331   \n",
       "7                     0.333333             0.411765           0.530084   \n",
       "11                    0.200000             0.200000           0.431476   \n",
       "17                    0.380952             0.380952           0.472186   \n",
       "...                        ...                  ...                ...   \n",
       "3050                  0.521739             0.590909           0.679918   \n",
       "98                    0.565217             0.565217           0.692113   \n",
       "607                   0.714286             0.714286           0.765723   \n",
       "1505                  0.600000             0.600000           0.713112   \n",
       "538                   0.555556             0.647059           0.689547   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "3                             0.681597                         0.526984   \n",
       "5                             0.880645                         0.860215   \n",
       "7                             0.706279                         0.581481   \n",
       "11                            0.600000                         0.475926   \n",
       "17                            0.878325                         0.732465   \n",
       "...                                ...                              ...   \n",
       "3050                          0.858281                         0.801351   \n",
       "98                            0.860529                         0.773677   \n",
       "607                           0.837912                         0.819414   \n",
       "1505                          0.744528                         0.704315   \n",
       "538                           0.802381                         0.809524   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "3                                 0.577681  \n",
       "5                                 0.870430  \n",
       "7                                 0.637763  \n",
       "11                                0.537963  \n",
       "17                                0.805395  \n",
       "...                                    ...  \n",
       "3050                              0.829816  \n",
       "98                                0.815251  \n",
       "607                               0.826127  \n",
       "1505                              0.715877  \n",
       "538                               0.805952  \n",
       "\n",
       "[1810 rows x 20 columns]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1SampleMissing = subset1Missing.sample(n=905,random_state=42)\n",
    "new_train_df_Missing = subset0Missing.append(subset1SampleMissing)\n",
    "new_train_df_Missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d296dd-5474-4b57-ae04-9605762123f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5874652-a244-4dac-9da7-a9871ff6a390",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28b7617f-32a7-412d-be0f-a69f27950a25",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset with Other Preprocessing Method Version 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "92638d5c-de16-4ca8-9ff2-f58c58c372c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df3 = pd.read_csv(\"../Data/train_with_label.txt\", delimiter = \"r'\\t\", header = None, engine = 'python')\n",
    "train_df3 = train_df3[0].str.split(\"\\t\", expand=True)\n",
    "train_df3 = train_df3.rename(columns={0: \"id\", 1: \"sentence1\", 2: \"sentence2\", 3: \"classification\"})\n",
    "train_df3[\"classification\"] = pd.to_numeric(train_df3[\"classification\"])\n",
    "train_df3.drop_duplicates(inplace = True)\n",
    "train_df3\n",
    "\n",
    "#Text Cleaning Features:\n",
    "train_df3['Text_Cleaned1'] = list(map(thePreprocessorNoLemma, train_df3.sentence1))\n",
    "train_df3['Text_Cleaned2'] = list(map(thePreprocessorNoLemma, train_df3.sentence2))\n",
    "train_df3['lemmatized_text1'] = list(map(thePreprocessorLemma, train_df3.sentence1))\n",
    "train_df3['lemmatized_text2'] = list(map(thePreprocessorLemma, train_df3.sentence2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8c5defce-db94-4869-bd12-9008c57448bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Syntactic Features:\n",
    "train_df3['cosine_similarity_score'] = list(map(counter_cosine_similarity, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['length_similarity'] = list(map(length_similarity, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['overlap_score'] = list(map(overlap_score, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['overlap2_score'] = list(map(overlap2_score, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['cosine/length_ratio'] = list(map(similarity_score, train_df3.length_similarity, train_df3.cosine_similarity_score))\n",
    "train_df3['cosine_similarity_score2'] = list(map(compute_cosine_similarity, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['jaccard_similarity_score'] = list(map(compute_jaccard_similarity, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2))\n",
    "train_df3['lemma_jaccard_score'] = list(map(compute_lemma_jaccard_similarity, train_df3.lemmatized_text1, train_df3.lemmatized_text2))\n",
    "train_df3['overall_sim_score'] = list(map(overall_similarity_combined, train_df3.Text_Cleaned1, train_df3.Text_Cleaned2, train_df3.lemmatized_text1, train_df3.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "b56e6d31-11ae-49ee-86f9-9a5d0d833e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Semantic Features:\n",
    "pdf1 = train_df3.iloc[:800]\n",
    "pdf2 = train_df3.iloc[800:1600]\n",
    "pdf3 = train_df3.iloc[1600:2400]\n",
    "pdf4 = train_df3.iloc[2400:3200]\n",
    "pdf5 = train_df3.iloc[3200:4077]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "308f8a8d-de7d-47ed-a9d2-ce4a08f526f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf1['scores'] = list(map(semantic_similarities, pdf1.lemmatized_text1, pdf1.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "14470121-73e9-4a37-902b-adb5fc8fcd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf2['scores'] = list(map(semantic_similarities, pdf2.lemmatized_text1, pdf2.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "0346f2ea-213f-4fea-8147-aa21e1e48053",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf3['scores'] = list(map(semantic_similarities, pdf3.lemmatized_text1, pdf3.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "cf43801b-6764-4b34-89a8-02d41704f82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf4['scores'] = list(map(semantic_similarities, pdf4.lemmatized_text1, pdf4.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6f48f8c8-a33a-476d-9c19-e61c9fb0620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf5['scores'] = list(map(semantic_similarities, pdf5.lemmatized_text1, pdf5.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "000e3281-a6d0-4eed-b027-e5560ebd76b4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[The, Democratic, candidates, also, began, ann...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "      <td>[democratic, candidate, also, begin, announce,...</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.441176</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.855750</td>\n",
       "      <td>0.906994</td>\n",
       "      <td>0.902778</td>\n",
       "      <td>0.904886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[The, woman, exposed, SARS, virus, hospital, h...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health,...</td>\n",
       "      <td>[woman, expose, sars, virus, hospital, health-...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.368421</td>\n",
       "      <td>0.649519</td>\n",
       "      <td>0.962250</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.732871</td>\n",
       "      <td>0.914216</td>\n",
       "      <td>0.921569</td>\n",
       "      <td>0.917892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>[He, said, problem, needs, corrected, space, s...</td>\n",
       "      <td>[He, said, prob, lem, needs, corrected, space,...</td>\n",
       "      <td>[say, problem, need, correct, space, shuttle, ...</td>\n",
       "      <td>[say, prob, lem, need, correct, space, shuttle...</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.724942</td>\n",
       "      <td>0.792256</td>\n",
       "      <td>0.664021</td>\n",
       "      <td>0.721825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[A, representative, Phoenix-based, U-Haul, dec...</td>\n",
       "      <td>[Anthony, Citrano, representative, WhenU, decl...</td>\n",
       "      <td>[representative, phoenix-based, u-haul, declin...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.613296</td>\n",
       "      <td>0.523529</td>\n",
       "      <td>0.561639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[The, biggest, threat, order, seemed, looting,...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "      <td>[big, threat, order, seem, loot, crime, includ...</td>\n",
       "      <td>0.739940</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.199095</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.565837</td>\n",
       "      <td>0.874475</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.669659</td>\n",
       "      <td>0.771062</td>\n",
       "      <td>0.737500</td>\n",
       "      <td>0.754281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[Axelrod, died, heart, failure, asleep, Los, A...</td>\n",
       "      <td>[axelrod, die, sleep, heart, failure, say, dau...</td>\n",
       "      <td>[axelrod, die, heart, failure, asleep, los, an...</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.567460</td>\n",
       "      <td>0.493651</td>\n",
       "      <td>0.518707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Saddam, 's, son, Odai, surrendered, Friday, A...</td>\n",
       "      <td>[Hussein, 's, son, Uday, surrendered, yesterda...</td>\n",
       "      <td>[saddam, 's, son, odai, surrender, friday, ame...</td>\n",
       "      <td>[hussein, 's, son, uday, surrender, yesterday,...</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.848856</td>\n",
       "      <td>0.847222</td>\n",
       "      <td>0.847222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1</td>\n",
       "      <td>[If, Senator, Clinton, decide, run, 2008, anno...</td>\n",
       "      <td>[If, Mrs, Clinton, decide, contest, 2008, elec...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, announce...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "      <td>0.800641</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.739053</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.834569</td>\n",
       "      <td>0.789855</td>\n",
       "      <td>0.809704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1</td>\n",
       "      <td>[The, Iranian, refugee, sewed, eyes, lips, ear...</td>\n",
       "      <td>[An, Iranian, Kurd, stitched, eyes, lips, ears...</td>\n",
       "      <td>[iranian, refugee, sew, eye, lip, ear, protest...</td>\n",
       "      <td>[iranian, kurd, stitch, eye, lip, ear, protest...</td>\n",
       "      <td>0.518875</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.259259</td>\n",
       "      <td>0.481812</td>\n",
       "      <td>0.963624</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.567504</td>\n",
       "      <td>0.700889</td>\n",
       "      <td>0.562857</td>\n",
       "      <td>0.631617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Gemstar, 's, shares, gathered, 2.6, percent, ...</td>\n",
       "      <td>[Gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, 's, share, gather, 2.6, percent, add...</td>\n",
       "      <td>[gemstar, share, move, higher, news, close, 2....</td>\n",
       "      <td>0.476731</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.433392</td>\n",
       "      <td>0.953463</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.555321</td>\n",
       "      <td>0.483069</td>\n",
       "      <td>0.434921</td>\n",
       "      <td>0.454762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4077 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...               1   \n",
       "1     The woman was exposed to the SARS virus while ...               1   \n",
       "2     He said the prob lem needs to be corrected bef...               1   \n",
       "3     Anthony Citrano , a representative for WhenU ,...               0   \n",
       "4     The biggest threat to order seemed to be looti...               1   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...               1   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...               1   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...               1   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...               1   \n",
       "4076  Gemstar shares moved higher on the news , clos...               1   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, problem, needs, corrected, space, s...   \n",
       "3     [A, representative, Phoenix-based, U-Haul, dec...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [Saddam, 's, son, Odai, surrendered, Friday, A...   \n",
       "4074  [If, Senator, Clinton, decide, run, 2008, anno...   \n",
       "4075  [The, Iranian, refugee, sewed, eyes, lips, ear...   \n",
       "4076  [Gemstar, 's, shares, gathered, 2.6, percent, ...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [The, Democratic, candidates, also, began, ann...   \n",
       "1     [The, woman, exposed, SARS, virus, hospital, h...   \n",
       "2     [He, said, prob, lem, needs, corrected, space,...   \n",
       "3     [Anthony, Citrano, representative, WhenU, decl...   \n",
       "4     [The, biggest, threat, order, seemed, looting,...   \n",
       "...                                                 ...   \n",
       "4072  [Axelrod, died, heart, failure, asleep, Los, A...   \n",
       "4073  [Hussein, 's, son, Uday, surrendered, yesterda...   \n",
       "4074  [If, Mrs, Clinton, decide, contest, 2008, elec...   \n",
       "4075  [An, Iranian, Kurd, stitched, eyes, lips, ears...   \n",
       "4076  [Gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, begin, announce,...   \n",
       "1     [woman, expose, sars, virus, hospital, health,...   \n",
       "2     [say, problem, need, correct, space, shuttle, ...   \n",
       "3     [representative, phoenix-based, u-haul, declin...   \n",
       "4     [big, threat, order, seem, loot, crime, includ...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, die, sleep, heart, failure, say, dau...   \n",
       "4073  [saddam, 's, son, odai, surrender, friday, ame...   \n",
       "4074  [senator, clinton, decide, run, 2008, announce...   \n",
       "4075  [iranian, refugee, sew, eye, lip, ear, protest...   \n",
       "4076  [gemstar, 's, share, gather, 2.6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "0     [democratic, candidate, also, begin, announce,...   \n",
       "1     [woman, expose, sars, virus, hospital, health-...   \n",
       "2     [say, prob, lem, need, correct, space, shuttle...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [big, threat, order, seem, loot, crime, includ...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, die, heart, failure, asleep, los, an...   \n",
       "4073  [hussein, 's, son, uday, surrender, yesterday,...   \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...   \n",
       "4075  [iranian, kurd, stitch, eye, lip, ear, protest...   \n",
       "4076  [gemstar, share, move, higher, news, close, 2....   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                    0.882353           1.000000       0.000000   \n",
       "1                    0.721688           0.900000       0.077778   \n",
       "2                    0.700000           1.000000       0.000000   \n",
       "3                    0.455842           0.636364       0.207792   \n",
       "4                    0.739940           0.764706       0.199095   \n",
       "...                       ...                ...            ...   \n",
       "4072                 0.805823           0.750000       0.222222   \n",
       "4073                 0.714286           1.000000       0.000000   \n",
       "4074                 0.800641           0.923077       0.064103   \n",
       "4075                 0.518875           0.928571       0.038462   \n",
       "4076                 0.476731           0.909091       0.045455   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0           0.441176             0.882353                  1.000000   \n",
       "1           0.368421             0.649519                  0.962250   \n",
       "2           0.350000             0.700000                  1.000000   \n",
       "3           0.222222             0.290081                  0.797724   \n",
       "4           0.366667             0.565837                  0.874475   \n",
       "...              ...                  ...                       ...   \n",
       "4072        0.380952             0.604367                  0.886405   \n",
       "4073        0.333333             0.714286                  1.000000   \n",
       "4074        0.400000             0.739053                  0.960769   \n",
       "4075        0.259259             0.481812                  0.963624   \n",
       "4076        0.238095             0.433392                  0.953463   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "0                     0.789474             0.777778           0.855750   \n",
       "1                     0.636364             0.600000           0.732871   \n",
       "2                     0.538462             0.636364           0.724942   \n",
       "3                     0.285714             0.307692           0.463710   \n",
       "4                     0.578947             0.555556           0.669659   \n",
       "...                        ...                  ...                ...   \n",
       "4072                  0.583333             0.583333           0.684357   \n",
       "4073                  0.466667             0.466667           0.644444   \n",
       "4074                  0.666667             0.642857           0.756764   \n",
       "4075                  0.350000             0.388889           0.567504   \n",
       "4076                  0.312500             0.400000           0.555321   \n",
       "\n",
       "      overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "0                             0.906994                         0.902778   \n",
       "1                             0.914216                         0.921569   \n",
       "2                             0.792256                         0.664021   \n",
       "3                             0.613296                         0.523529   \n",
       "4                             0.771062                         0.737500   \n",
       "...                                ...                              ...   \n",
       "4072                          0.567460                         0.493651   \n",
       "4073                          0.848856                         0.847222   \n",
       "4074                          0.834569                         0.789855   \n",
       "4075                          0.700889                         0.562857   \n",
       "4076                          0.483069                         0.434921   \n",
       "\n",
       "      overall_similarity_combined_semantic  \n",
       "0                                 0.904886  \n",
       "1                                 0.917892  \n",
       "2                                 0.721825  \n",
       "3                                 0.561639  \n",
       "4                                 0.754281  \n",
       "...                                    ...  \n",
       "4072                              0.518707  \n",
       "4073                              0.847222  \n",
       "4074                              0.809704  \n",
       "4075                              0.631617  \n",
       "4076                              0.454762  \n",
       "\n",
       "[4077 rows x 20 columns]"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df3 = pdf1.append(pdf2).append(pdf3).append(pdf4).append(pdf5)\n",
    "train_df3[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']] = pd.DataFrame(train_df3.scores.tolist(), index= train_df3.index)\n",
    "train_df3.drop(['scores'], axis=1, inplace=True)\n",
    "train_df3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c712b6e5-3ed0-40b7-a464-865d464f30f9",
   "metadata": {},
   "source": [
    "## 50-50 Randomly Removing Majority Class Training Dataset with Other Preprocessing Method Version 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "d468f907-e188-46bc-8a35-8d77bf4fcc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset0_3 = train_df3.loc[train_df3['classification'] == 0]\n",
    "subset1_3 = train_df3.loc[train_df3['classification'] == 1]\n",
    "subset1Sample_3 = subset1_3.sample(n=1039,random_state=42)\n",
    "new_train_df_3 = subset0_3.append(subset1Sample_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c07067-bc04-4e00-93cd-bf2f24757b4e",
   "metadata": {},
   "source": [
    "## Preprocessing of Normal Training Dataset with Other Preprocessing Method Version 3, Outliers Removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "18e41aa1-1e0f-4630-9c4c-a4e104f590e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "628"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset0_clean_3 = remove_outliers(subset0_3, 'cosine_similarity_score', .05,.95)\n",
    "# #subset0_clean_3 = remove_outliers(subset0_clean_3, 'length_similarity', .05,.95)\n",
    "subset0_clean_3 = remove_outliers(subset0_3, 'overlap_score', .00,.90)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3, 'overlap2_score', .05,.95)\n",
    "subset0_clean_3 = remove_outliers(subset0_clean_3, 'cosine/length_ratio', .00,.90)\n",
    "# #subset0_clean_3 = remove_outliers(subset0_clean_3, 'cosine_similarity_score2', .05,.95)\n",
    "subset0_clean_3 = remove_outliers(subset0_clean_3, 'jaccard_similarity_score', .00,.90)\n",
    "subset0_clean_3 = remove_outliers(subset0_clean_3, 'lemma_jaccard_score', .00,.90)\n",
    "subset0_clean_3 = remove_outliers(subset0_clean_3, 'overall_sim_score', .00,.90)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'bigram_similarity',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'jaccard_distance_trigrams',.05,.95)\n",
    "subset0_clean_3 = remove_outliers(subset0_clean_3,'cosine_similarity_trigrams', .00,.90)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'trigram_similarity',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset0_clean_3 = remove_outliers(subset0_clean_3,'quadgram_similarity',.05,.95)\n",
    "len(subset0_clean_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "59bf6f52-65f3-4800-bd11-3a8af13b0ebd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1641"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset1_clean_3 = remove_outliers(subset1_3, 'cosine_similarity_score', .05,.95)\n",
    "# #subset1_clean_3 = remove_outliers(subset1_clean_3, 'length_similarity', .05,.95)\n",
    "subset1_clean_3 = remove_outliers(subset1_3, 'overlap_score', .10,1.0)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3, 'overlap2_score', .05,.95)\n",
    "subset1_clean_3 = remove_outliers(subset1_clean_3, 'cosine/length_ratio', .10,1.0)\n",
    "# #subset1_clean_3 = remove_outliers(subset1_clean_3, 'cosine_similarity_score2', .05,.95)\n",
    "subset1_clean_3 = remove_outliers(subset1_clean_3, 'jaccard_similarity_score', .10,1.0)\n",
    "subset1_clean_3 = remove_outliers(subset1_clean_3, 'lemma_jaccard_score', .10,1.0)\n",
    "subset1_clean_3 = remove_outliers(subset1_clean_3, 'overall_sim_score', .10,1.0)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3, 'overall_similarity_combined_semantic', .05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3, 'overall_similarity_wup_semantic', .05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3, 'overall_similarity_path_semantic', .05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'jaccard_distance_bigrams',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'cosine_similarity_bigrams',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'bigram_similarity',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'jaccard_distance_trigrams',.05,.95)\n",
    "subset1_clean_3 = remove_outliers(subset1_clean_3,'cosine_similarity_trigrams',.10,1.0)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'trigram_similarity',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'jaccard_distance_quadgrams',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'cosine_similarity_quadgrams',.05,.95)\n",
    "# subset1_clean_3 = remove_outliers(subset1_clean_3,'quadgram_similarity',.05,.95)\n",
    "len(subset1_clean_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "51f757ad-dd42-4c58-be6d-439f989345f6",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.590351</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.812030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.481292</td>\n",
       "      <td>0.284605</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.457632</td>\n",
       "      <td>0.274986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>1</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.736979</td>\n",
       "      <td>0.726184</td>\n",
       "      <td>0.240192</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4063</th>\n",
       "      <td>1</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.854779</td>\n",
       "      <td>0.876714</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>1</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.239046</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>1</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.644444</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.756764</td>\n",
       "      <td>0.739053</td>\n",
       "      <td>0.421637</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.935897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2269 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.307692           0.463710   \n",
       "7                  0             0.312500           0.514166   \n",
       "8                  0             0.421053           0.590351   \n",
       "11                 0             0.307692           0.481292   \n",
       "17                 0             0.315789           0.457632   \n",
       "...              ...                  ...                ...   \n",
       "4062               1             0.611111           0.736979   \n",
       "4063               1             0.812500           0.854779   \n",
       "4072               1             0.583333           0.684357   \n",
       "4073               1             0.466667           0.644444   \n",
       "4074               1             0.642857           0.756764   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.158114   \n",
       "7                0.404796                    0.119523   \n",
       "8                0.442105                    0.226134   \n",
       "11               0.284605                    0.154303   \n",
       "17               0.274986                    0.000000   \n",
       "...                   ...                         ...   \n",
       "4062             0.726184                    0.240192   \n",
       "4063             0.876714                    0.692308   \n",
       "4072             0.604367                    0.239046   \n",
       "4073             0.714286                    0.200000   \n",
       "4074             0.739053                    0.421637   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.352941       0.861538  \n",
       "8                     0.450000       0.812030  \n",
       "11                    0.187500       0.966667  \n",
       "17                    0.350000       0.688889  \n",
       "...                        ...            ...  \n",
       "4062                  0.631579       0.950000  \n",
       "4063                  0.812500       1.000000  \n",
       "4072                  0.583333       0.777778  \n",
       "4073                  0.466667       1.000000  \n",
       "4074                  0.666667       0.935897  \n",
       "\n",
       "[2269 rows x 7 columns]"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_train_df_clean_3 = subset0_clean_3.append(subset1_clean_3)\n",
    "new_train_df_clean_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b5726c-12a0-4530-b928-4ddde52b0918",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab5833a-358b-462c-9548-2bbe4a040f43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b450d2e-211e-494d-bede-dfbca12f0ccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b48705c9-3ef6-4903-b0db-b737490b730d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class and Outlier Removal for Normal Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "99ff55c2-30da-45ef-991d-07e229920200",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.551413</td>\n",
       "      <td>0.324459</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.801136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.698932</td>\n",
       "      <td>0.577350</td>\n",
       "      <td>0.717137</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.639955</td>\n",
       "      <td>0.566072</td>\n",
       "      <td>0.201008</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.888112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>1</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.638391</td>\n",
       "      <td>0.513809</td>\n",
       "      <td>0.462250</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.781818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>1</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.890619</td>\n",
       "      <td>0.865181</td>\n",
       "      <td>0.759072</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.944853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.817554</td>\n",
       "      <td>0.757672</td>\n",
       "      <td>0.688847</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.907121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1280 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.285714           0.456384   \n",
       "7                  0             0.411765           0.530084   \n",
       "8                  0             0.388889           0.551413   \n",
       "11                 0             0.200000           0.431476   \n",
       "17                 0             0.380952           0.472186   \n",
       "...              ...                  ...                ...   \n",
       "101                1             0.615385           0.698932   \n",
       "3964               1             0.500000           0.639955   \n",
       "333                1             0.529412           0.638391   \n",
       "3889               1             0.875000           0.890619   \n",
       "1703               1             0.750000           0.817554   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.149071   \n",
       "7                0.362209                    0.204124   \n",
       "8                0.324459                    0.267261   \n",
       "11               0.268328                    0.000000   \n",
       "17               0.360060                    0.000000   \n",
       "...                   ...                         ...   \n",
       "101              0.577350                    0.717137   \n",
       "3964             0.566072                    0.201008   \n",
       "333              0.513809                    0.462250   \n",
       "3889             0.865181                    0.759072   \n",
       "1703             0.757672                    0.688847   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.333333       0.828571  \n",
       "8                     0.388889       0.801136  \n",
       "11                    0.200000       0.925000  \n",
       "17                    0.380952       0.700000  \n",
       "...                        ...            ...  \n",
       "101                   0.615385       0.777778  \n",
       "3964                  0.500000       0.888112  \n",
       "333                   0.529412       0.781818  \n",
       "3889                  0.823529       0.944853  \n",
       "1703                  0.750000       0.907121  \n",
       "\n",
       "[1280 rows x 7 columns]"
      ]
     },
     "execution_count": 357,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1SampleNormalOutlier = subset1_clean.sample(n=len(subset0_clean), random_state=42)\n",
    "new_train_df_clean_randomUnder = subset0_clean.append(subset1SampleNormalOutlier)\n",
    "new_train_df_clean_randomUnder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf98c64-7d47-4fcc-b7d0-fe2e7e5d4b91",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class and Outlier Removal for Training Dataset with Other Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "id": "dd9732ca-46cb-47d2-9256-00de3be06952",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.590351</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.812030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.481292</td>\n",
       "      <td>0.284605</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.457632</td>\n",
       "      <td>0.274986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>1</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.653754</td>\n",
       "      <td>0.714435</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.704281</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.685243</td>\n",
       "      <td>0.608581</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>1</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.866794</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.381385</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.657318</td>\n",
       "      <td>0.632714</td>\n",
       "      <td>0.298142</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.307692           0.463710   \n",
       "7                  0             0.312500           0.514166   \n",
       "8                  0             0.421053           0.590351   \n",
       "11                 0             0.307692           0.481292   \n",
       "17                 0             0.315789           0.457632   \n",
       "...              ...                  ...                ...   \n",
       "3761               1             0.692308           0.745518   \n",
       "1511               1             0.642857           0.704281   \n",
       "725                1             0.571429           0.685243   \n",
       "3299               1             0.846154           0.866794   \n",
       "3877               1             0.500000           0.657318   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.158114   \n",
       "7                0.404796                    0.119523   \n",
       "8                0.442105                    0.226134   \n",
       "11               0.284605                    0.154303   \n",
       "17               0.274986                    0.000000   \n",
       "...                   ...                         ...   \n",
       "3761             0.653754                    0.714435   \n",
       "1511             0.622276                    0.288675   \n",
       "725              0.608581                    0.223607   \n",
       "3299             0.833008                    0.381385   \n",
       "3877             0.632714                    0.298142   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.352941       0.861538  \n",
       "8                     0.450000       0.812030  \n",
       "11                    0.187500       0.966667  \n",
       "17                    0.350000       0.688889  \n",
       "...                        ...            ...  \n",
       "3761                  0.642857       0.805195  \n",
       "1511                  0.562500       0.833333  \n",
       "725                   0.571429       0.866667  \n",
       "3299                  0.857143       0.934066  \n",
       "3877                  0.550000       0.866667  \n",
       "\n",
       "[1256 rows x 7 columns]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1SampleOutlier_2 = subset1_clean_2.sample(n=len(subset0_clean_2), random_state=42)\n",
    "new_train_df_2_clean_randomUnder = subset0_clean_2.append(subset1SampleOutlier_2)\n",
    "new_train_df_2_clean_randomUnder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ebd2e3-43cb-4e9d-888a-1d68ae343693",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class and Outlier Removal for Training Dataset with Other Preprocessing Version 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "2a8fe438-1dd9-486e-934a-0210f3f6ed1d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.463710</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.158114</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.514166</td>\n",
       "      <td>0.404796</td>\n",
       "      <td>0.119523</td>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.861538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.590351</td>\n",
       "      <td>0.442105</td>\n",
       "      <td>0.226134</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.812030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.481292</td>\n",
       "      <td>0.284605</td>\n",
       "      <td>0.154303</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.966667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0</td>\n",
       "      <td>0.315789</td>\n",
       "      <td>0.457632</td>\n",
       "      <td>0.274986</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.688889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3761</th>\n",
       "      <td>1</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.745518</td>\n",
       "      <td>0.653754</td>\n",
       "      <td>0.714435</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.805195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>1</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.704281</td>\n",
       "      <td>0.622276</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>725</th>\n",
       "      <td>1</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.685243</td>\n",
       "      <td>0.608581</td>\n",
       "      <td>0.223607</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>1</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.866794</td>\n",
       "      <td>0.833008</td>\n",
       "      <td>0.381385</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.934066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.657318</td>\n",
       "      <td>0.632714</td>\n",
       "      <td>0.298142</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1256 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                  0             0.307692           0.463710   \n",
       "7                  0             0.312500           0.514166   \n",
       "8                  0             0.421053           0.590351   \n",
       "11                 0             0.307692           0.481292   \n",
       "17                 0             0.315789           0.457632   \n",
       "...              ...                  ...                ...   \n",
       "3761               1             0.692308           0.745518   \n",
       "1511               1             0.642857           0.704281   \n",
       "725                1             0.571429           0.685243   \n",
       "3299               1             0.846154           0.866794   \n",
       "3877               1             0.500000           0.657318   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.158114   \n",
       "7                0.404796                    0.119523   \n",
       "8                0.442105                    0.226134   \n",
       "11               0.284605                    0.154303   \n",
       "17               0.274986                    0.000000   \n",
       "...                   ...                         ...   \n",
       "3761             0.653754                    0.714435   \n",
       "1511             0.622276                    0.288675   \n",
       "725              0.608581                    0.223607   \n",
       "3299             0.833008                    0.381385   \n",
       "3877             0.632714                    0.298142   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.352941       0.861538  \n",
       "8                     0.450000       0.812030  \n",
       "11                    0.187500       0.966667  \n",
       "17                    0.350000       0.688889  \n",
       "...                        ...            ...  \n",
       "3761                  0.642857       0.805195  \n",
       "1511                  0.562500       0.833333  \n",
       "725                   0.571429       0.866667  \n",
       "3299                  0.857143       0.934066  \n",
       "3877                  0.550000       0.866667  \n",
       "\n",
       "[1256 rows x 7 columns]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1SampleOutlier_3 = subset1_clean_3.sample(n=len(subset0_clean_3), random_state=42)\n",
    "new_train_df_3_clean_randomUnder = subset0_clean_3.append(subset1SampleOutlier_3)\n",
    "new_train_df_3_clean_randomUnder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df46aa93-104e-4854-a3b0-f1f417df2571",
   "metadata": {},
   "source": [
    "## Preprocessing of 50-50 Randomly Removing Majority Class and Outlier Removal for Missing Training Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "a6440235-ab97-40a2-a0f3-b3ed09ccca2e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classification</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_trigrams</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.149071</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.792208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.530084</td>\n",
       "      <td>0.362209</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.431476</td>\n",
       "      <td>0.268328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.925000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.472186</td>\n",
       "      <td>0.360060</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.513111</td>\n",
       "      <td>0.341096</td>\n",
       "      <td>0.314270</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.631818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2252</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.690299</td>\n",
       "      <td>0.596285</td>\n",
       "      <td>0.526235</td>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2108</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.697770</td>\n",
       "      <td>0.643097</td>\n",
       "      <td>0.231455</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.901786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.821609</td>\n",
       "      <td>0.760024</td>\n",
       "      <td>0.385758</td>\n",
       "      <td>0.764706</td>\n",
       "      <td>0.883929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2297</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.859846</td>\n",
       "      <td>0.760726</td>\n",
       "      <td>0.603023</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1124 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      classification  lemma_jaccard_score  overall_sim_score  \\\n",
       "3                0.0             0.285714           0.456384   \n",
       "7                0.0             0.411765           0.530084   \n",
       "10               0.0             0.200000           0.431476   \n",
       "15               0.0             0.380952           0.472186   \n",
       "19               0.0             0.428571           0.513111   \n",
       "...              ...                  ...                ...   \n",
       "2252             1.0             0.588235           0.690299   \n",
       "2108             1.0             0.578947           0.697770   \n",
       "1436             1.0             0.764706           0.821609   \n",
       "3180             1.0             0.733333           0.822222   \n",
       "2297             1.0             0.833333           0.859846   \n",
       "\n",
       "      cosine/length_ratio  cosine_similarity_trigrams  \\\n",
       "3                0.290081                    0.149071   \n",
       "7                0.362209                    0.204124   \n",
       "10               0.268328                    0.000000   \n",
       "15               0.360060                    0.000000   \n",
       "19               0.341096                    0.314270   \n",
       "...                   ...                         ...   \n",
       "2252             0.596285                    0.526235   \n",
       "2108             0.643097                    0.231455   \n",
       "1436             0.760024                    0.385758   \n",
       "3180             0.875000                    0.500000   \n",
       "2297             0.760726                    0.603023   \n",
       "\n",
       "      jaccard_similarity_score  overlap_score  \n",
       "3                     0.285714       0.792208  \n",
       "7                     0.333333       0.828571  \n",
       "10                    0.200000       0.925000  \n",
       "15                    0.380952       0.700000  \n",
       "19                    0.428571       0.631818  \n",
       "...                        ...            ...  \n",
       "2252                  0.588235       0.833333  \n",
       "2108                  0.578947       0.901786  \n",
       "1436                  0.764706       0.883929  \n",
       "3180                  0.733333       1.000000  \n",
       "2297                  0.833333       0.833333  \n",
       "\n",
       "[1124 rows x 7 columns]"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset1SampleMissingOutlier = subset1_clean_Missing.sample(n=len(subset0_clean_Missing), random_state=42)\n",
    "missing_clean_randomUnder = subset0_clean_Missing.append(subset1SampleMissingOutlier)\n",
    "missing_clean_randomUnder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953c295e-c072-425f-8050-e48960240f34",
   "metadata": {},
   "source": [
    "## N-Grams Features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ee1a23f8-6c9d-44a4-a1c6-e349cbe12c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams \n",
    "def produce_ngrams(token,n):\n",
    "    output = list(ngrams(token, n))\n",
    "    return output\n",
    "def produce_bigrams(token,n=2):\n",
    "    output = list(ngrams(token, n))\n",
    "    return output\n",
    "def produce_trigrams(token,n=3):\n",
    "    output = list(ngrams(token, n))\n",
    "    return output\n",
    "def produce_quadgrams(token,n=4):\n",
    "    output = list(ngrams(token, n))\n",
    "    return output\n",
    "def jaccard_distance_ngrams(a, b):\n",
    "    \"\"\"Calculate the jaccard distance between sets A and B\"\"\"\n",
    "    a = set(a)\n",
    "    b = set(b)\n",
    "    return 1.0 * len(a&b)/len(a|b)\n",
    "def cosine_similarity_ngrams(a, b):\n",
    "    vec1 = Counter(a)\n",
    "    vec2 = Counter(b)\n",
    "    \n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = sum([vec1[x] * vec2[x] for x in intersection])\n",
    "\n",
    "    sum1 = sum([vec1[x]**2 for x in vec1.keys()])\n",
    "    sum2 = sum([vec2[x]**2 for x in vec2.keys()])\n",
    "    denominator = math.sqrt(sum1) * math.sqrt(sum2)\n",
    "\n",
    "    if not denominator:\n",
    "        return 0.0\n",
    "    return float(numerator) / denominator\n",
    "def ngram_similarity(a,b):\n",
    "    vec1 = Counter(a)\n",
    "    vec2 = Counter(b)\n",
    "    intersection = set(vec1.keys()) & set(vec2.keys())\n",
    "    numerator = len(intersection)\n",
    "    denominator = len(vec1) + len(vec2)\n",
    "    return numerator/denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "dccb66ab-68db-4d3a-b96e-d0304b493f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [train_df,new_train_df,new_train_df_clean,subset0,subset1,train_df2,subset0_2,subset1_2,new_train_df_2,new_train_df_clean_2,missing_train,missing,new_train_df_clean_Missing,new_train_df_Missing,dev_df,new_train_df_clean_randomUnder,new_train_df_2_clean_randomUnder,missing_clean_randomUnder, train_df3,new_train_df_3,new_train_df_clean_3,new_train_df_3_clean_randomUnder]\n",
    "for df in dfs:\n",
    "    df['bigrams1'] = list(map(produce_bigrams, df.lemmatized_text1))\n",
    "    df['bigrams2'] = list(map(produce_bigrams, df.lemmatized_text2))\n",
    "    df['jaccard_distance_bigrams'] = list(map(jaccard_distance_ngrams, df.bigrams1, df.bigrams2))\n",
    "    df['cosine_similarity_bigrams'] = list(map(cosine_similarity_ngrams, df.bigrams1, df.bigrams2))\n",
    "    df['bigram_similarity'] = list(map(ngram_similarity, df.bigrams1, df.bigrams2))\n",
    "    \n",
    "    df['trigrams1'] = list(map(produce_trigrams, df.lemmatized_text1))\n",
    "    df['trigrams2'] = list(map(produce_trigrams, df.lemmatized_text2))\n",
    "    df['jaccard_distance_trigrams'] = list(map(jaccard_distance_ngrams, df.trigrams1, df.trigrams2))\n",
    "    df['cosine_similarity_trigrams'] = list(map(cosine_similarity_ngrams, df.trigrams1, df.trigrams2))\n",
    "    df['trigram_similarity'] = list(map(ngram_similarity, df.trigrams1, df.trigrams2))\n",
    "    \n",
    "    df['quadgrams1'] = list(map(produce_quadgrams, df.lemmatized_text1))\n",
    "    df['quadgrams2'] = list(map(produce_quadgrams, df.lemmatized_text2))\n",
    "    df['jaccard_distance_quadgrams'] = list(map(jaccard_distance_ngrams, df.quadgrams1, df.quadgrams2))\n",
    "    df['cosine_similarity_quadgrams'] = list(map(cosine_similarity_ngrams, df.quadgrams1, df.quadgrams2))\n",
    "    df['quadgram_similarity'] = list(map(ngram_similarity, df.quadgrams1, df.quadgrams2))\n",
    "    \n",
    "    df.drop(['bigrams1', 'bigrams2', 'trigrams1', 'trigrams2', 'quadgrams1', 'quadgrams2'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71076532-2bd8-4aee-8240-dc416ee72cae",
   "metadata": {},
   "source": [
    "## Adjustments to Datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "d97a5bc1-c877-4db0-a156-4aaa6a435eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverting overlap and overlap2 scores:\n",
    "dfs = [train_df,new_train_df,new_train_df_clean,subset0,subset1,train_df2,subset0_2,subset1_2,new_train_df_2,new_train_df_clean_2,missing_train,missing,new_train_df_clean_Missing,new_train_df_Missing,dev_df,new_train_df_clean_randomUnder,new_train_df_2_clean_randomUnder,missing_clean_randomUnder, train_df3,new_train_df_3,new_train_df_clean_3,new_train_df_3_clean_randomUnder]\n",
    "for df in dfs:\n",
    "    df['overlap_score'] = list(map(overlap_score, df.Text_Cleaned1, df.Text_Cleaned2))\n",
    "    df['overlap2_score'] = list(map(overlap2_score, df.Text_Cleaned1, df.Text_Cleaned2))\n",
    "    df['overlap_score'] = 1 - df['overlap_score']\n",
    "    df['overlap2_score'] = 1 - df['overlap2_score']\n",
    "    #df.drop(['length_similarity', 'cosine_similarity_score2'], axis=1, inplace=True)\n",
    "    #df.drop(['jaccard_distance_bigrams','cosine_similarity_bigrams','bigram_similarity','jaccard_distance_trigrams','cosine_similarity_trigrams','trigram_similarity','jaccard_distance_quadgrams','cosine_similarity_quadgrams','quadgram_similarity'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "e21bce33-bd95-4bf4-8b00-efbd8f8f7657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing Semantic Features:\n",
    "for df in dfs:\n",
    "    min_max_scaler = preproc.MinMaxScaler()\n",
    "    df[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']] = min_max_scaler.fit_transform(df[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a48c2-3afe-4aa2-b469-8744760f9de1",
   "metadata": {},
   "source": [
    "### Development Dataset Pre-Processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "cf8d10ec-72dd-4f67-975c-f8ba5d7d21e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_df = pd.read_csv(\"../Data/dev_with_label.txt\", delimiter = \"r'\\t\", header = None, engine = 'python')\n",
    "dev_df = dev_df[0].str.split(\"\\t\", expand=True)\n",
    "dev_df = dev_df.rename(columns={0: \"id\", 1: \"sentence1\", 2: \"sentence2\", 3: \"classification\"})\n",
    "dev_df[\"classification\"] = pd.to_numeric(dev_df[\"classification\"])\n",
    "dev_df.drop_duplicates(inplace = True)\n",
    "dev_df\n",
    "\n",
    "lemm = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "#Syntactic Features:\n",
    "dev_df['Text_Cleaned1'] = list(map(clean_text, dev_df.sentence1))\n",
    "dev_df['lemmatized_text1'] = list(map(lambda word:list(map(lemm.lemmatize, word)),dev_df.Text_Cleaned1))\n",
    "dev_df['Text_Cleaned2'] = list(map(clean_text, dev_df.sentence2))\n",
    "dev_df['lemmatized_text2'] = list(map(lambda word:list(map(lemm.lemmatize, word)),dev_df.Text_Cleaned2))\n",
    "dev_df['cosine_similarity_score'] = list(map(counter_cosine_similarity, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['length_similarity'] = list(map(length_similarity, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['overlap_score'] = list(map(overlap_score, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['overlap2_score'] = list(map(overlap2_score, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['cosine/length_ratio'] = list(map(similarity_score, dev_df.length_similarity, dev_df.cosine_similarity_score))\n",
    "dev_df['cosine_similarity_score2'] = list(map(compute_cosine_similarity, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['jaccard_similarity_score'] = list(map(compute_jaccard_similarity, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "dev_df['lemma_jaccard_score'] = list(map(compute_lemma_jaccard_similarity, dev_df.lemmatized_text1, dev_df.lemmatized_text2))\n",
    "dev_df['overall_sim_score'] = list(map(overall_similarity_combined, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2, dev_df.lemmatized_text1, dev_df.lemmatized_text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "0963cc7b-9390-49f1-a3d6-d782fb8bb15b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_id_0</td>\n",
       "      <td>Local police authorities are treating the expl...</td>\n",
       "      <td>Acting New Haven Police Chief Francisco Ortiz ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[local, police, authorities, treating, explosi...</td>\n",
       "      <td>[local, police, authority, treating, explosion...</td>\n",
       "      <td>[acting, new, police, chief, francisco, ortiz,...</td>\n",
       "      <td>[acting, new, police, chief, francisco, ortiz,...</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.138889</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.400892</td>\n",
       "      <td>0.890871</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.519179</td>\n",
       "      <td>0.584580</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.526301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_id_1</td>\n",
       "      <td>The report shows that drugs sold in Canadian p...</td>\n",
       "      <td>The report shows that drugs sold in Canadian p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[report, shows, drugs, sold, canadian, pharmac...</td>\n",
       "      <td>[report, show, drug, sold, canadian, pharmacy,...</td>\n",
       "      <td>[report, shows, drugs, sold, canadian, pharmac...</td>\n",
       "      <td>[report, show, drug, sold, canadian, pharmacy,...</td>\n",
       "      <td>0.802955</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.151261</td>\n",
       "      <td>0.387097</td>\n",
       "      <td>0.661257</td>\n",
       "      <td>0.860309</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.803763</td>\n",
       "      <td>0.828098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_id_2</td>\n",
       "      <td>The transition is slated to begin no later tha...</td>\n",
       "      <td>A two-week transition period will begin no lat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[transition, slated, begin, later, june, 7, da...</td>\n",
       "      <td>[transition, slated, begin, later, june, 7, da...</td>\n",
       "      <td>[two, week, transition, period, begin, later, ...</td>\n",
       "      <td>[two, week, transition, period, begin, later, ...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.713095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_id_3</td>\n",
       "      <td>Like Viacom , GE -- parent of NBC -- is also s...</td>\n",
       "      <td>Like Viacom , General Electric is seen as a le...</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, viacom, ge, parent, nbc, also, seen, le...</td>\n",
       "      <td>[like, viacom, ge, parent, nbc, also, seen, le...</td>\n",
       "      <td>[like, viacom, general, electric, seen, less, ...</td>\n",
       "      <td>[like, viacom, general, electric, seen, le, en...</td>\n",
       "      <td>0.725241</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.175325</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.682968</td>\n",
       "      <td>0.796260</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>0.770524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_id_4</td>\n",
       "      <td>Last month , 62 Spanish peacekeepers died when...</td>\n",
       "      <td>In another disaster , 62 Spanish peacekeepers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[last, month, 62, spanish, peacekeepers, died,...</td>\n",
       "      <td>[last, month, 62, spanish, peacekeeper, died, ...</td>\n",
       "      <td>[another, disaster, 62, spanish, peacekeepers,...</td>\n",
       "      <td>[another, disaster, 62, spanish, peacekeeper, ...</td>\n",
       "      <td>0.585369</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.097902</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.495313</td>\n",
       "      <td>0.919866</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.581132</td>\n",
       "      <td>0.680159</td>\n",
       "      <td>0.603472</td>\n",
       "      <td>0.641237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>dev_id_719</td>\n",
       "      <td>He is a brother to three-year-old Mia , from K...</td>\n",
       "      <td>Winslet , 28 , has a three-year-old daughter M...</td>\n",
       "      <td>0</td>\n",
       "      <td>[brother, three, year, old, mia, kate, first, ...</td>\n",
       "      <td>[brother, three, year, old, mia, kate, first, ...</td>\n",
       "      <td>[winslet, 28, three, year, old, daughter, mia,...</td>\n",
       "      <td>[winslet, 28, three, year, old, daughter, mia,...</td>\n",
       "      <td>0.694365</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.595170</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>0.638645</td>\n",
       "      <td>0.598718</td>\n",
       "      <td>0.614469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>dev_id_720</td>\n",
       "      <td>Some 175 million shares traded on the Big Boar...</td>\n",
       "      <td>Some 1.6 billion shares traded on the Big Boar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[175, million, shares, traded, big, board, 7, ...</td>\n",
       "      <td>[175, million, share, traded, big, board, 7, p...</td>\n",
       "      <td>[1, 6, billion, shares, traded, big, board, 17...</td>\n",
       "      <td>[1, 6, billion, share, traded, big, board, 17,...</td>\n",
       "      <td>0.462910</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.396780</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.508607</td>\n",
       "      <td>0.720496</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.656723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>dev_id_721</td>\n",
       "      <td>Mr Berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>Mr Berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judges, inf...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judge, infl...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judges, inf...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judge, infl...</td>\n",
       "      <td>0.716115</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.102564</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.620633</td>\n",
       "      <td>0.930949</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.717347</td>\n",
       "      <td>0.706633</td>\n",
       "      <td>0.711990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>dev_id_722</td>\n",
       "      <td>He added that those \" are not solely American ...</td>\n",
       "      <td>\" These are not solely American principles nor...</td>\n",
       "      <td>1</td>\n",
       "      <td>[added, solely, american, principles, exclusiv...</td>\n",
       "      <td>[added, solely, american, principle, exclusive...</td>\n",
       "      <td>[solely, american, principles, exclusively, we...</td>\n",
       "      <td>[solely, american, principle, exclusively, wes...</td>\n",
       "      <td>0.771517</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.119048</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.925820</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.725273</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.804029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>dev_id_723</td>\n",
       "      <td>Memories also live on of the bloody debacle in...</td>\n",
       "      <td>Memories also live on of a bloody debacle in S...</td>\n",
       "      <td>1</td>\n",
       "      <td>[memories, also, live, bloody, debacle, somali...</td>\n",
       "      <td>[memory, also, live, bloody, debacle, somalia,...</td>\n",
       "      <td>[memories, also, live, bloody, debacle, somali...</td>\n",
       "      <td>[memory, also, live, bloody, debacle, somalia,...</td>\n",
       "      <td>0.828079</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.413793</td>\n",
       "      <td>0.772873</td>\n",
       "      <td>0.966092</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.828158</td>\n",
       "      <td>0.960591</td>\n",
       "      <td>0.928161</td>\n",
       "      <td>0.943897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          sentence1  \\\n",
       "0      dev_id_0  Local police authorities are treating the expl...   \n",
       "1      dev_id_1  The report shows that drugs sold in Canadian p...   \n",
       "2      dev_id_2  The transition is slated to begin no later tha...   \n",
       "3      dev_id_3  Like Viacom , GE -- parent of NBC -- is also s...   \n",
       "4      dev_id_4  Last month , 62 Spanish peacekeepers died when...   \n",
       "..          ...                                                ...   \n",
       "719  dev_id_719  He is a brother to three-year-old Mia , from K...   \n",
       "720  dev_id_720  Some 175 million shares traded on the Big Boar...   \n",
       "721  dev_id_721  Mr Berlusconi is accused of bribing judges to ...   \n",
       "722  dev_id_722  He added that those \" are not solely American ...   \n",
       "723  dev_id_723  Memories also live on of the bloody debacle in...   \n",
       "\n",
       "                                             sentence2  classification  \\\n",
       "0    Acting New Haven Police Chief Francisco Ortiz ...               0   \n",
       "1    The report shows that drugs sold in Canadian p...               1   \n",
       "2    A two-week transition period will begin no lat...               1   \n",
       "3    Like Viacom , General Electric is seen as a le...               1   \n",
       "4    In another disaster , 62 Spanish peacekeepers ...               1   \n",
       "..                                                 ...             ...   \n",
       "719  Winslet , 28 , has a three-year-old daughter M...               0   \n",
       "720  Some 1.6 billion shares traded on the Big Boar...               0   \n",
       "721  Mr Berlusconi is accused of bribing judges to ...               1   \n",
       "722  \" These are not solely American principles nor...               1   \n",
       "723  Memories also live on of a bloody debacle in S...               1   \n",
       "\n",
       "                                         Text_Cleaned1  \\\n",
       "0    [local, police, authorities, treating, explosi...   \n",
       "1    [report, shows, drugs, sold, canadian, pharmac...   \n",
       "2    [transition, slated, begin, later, june, 7, da...   \n",
       "3    [like, viacom, ge, parent, nbc, also, seen, le...   \n",
       "4    [last, month, 62, spanish, peacekeepers, died,...   \n",
       "..                                                 ...   \n",
       "719  [brother, three, year, old, mia, kate, first, ...   \n",
       "720  [175, million, shares, traded, big, board, 7, ...   \n",
       "721  [mr, berlusconi, accused, bribing, judges, inf...   \n",
       "722  [added, solely, american, principles, exclusiv...   \n",
       "723  [memories, also, live, bloody, debacle, somali...   \n",
       "\n",
       "                                      lemmatized_text1  \\\n",
       "0    [local, police, authority, treating, explosion...   \n",
       "1    [report, show, drug, sold, canadian, pharmacy,...   \n",
       "2    [transition, slated, begin, later, june, 7, da...   \n",
       "3    [like, viacom, ge, parent, nbc, also, seen, le...   \n",
       "4    [last, month, 62, spanish, peacekeeper, died, ...   \n",
       "..                                                 ...   \n",
       "719  [brother, three, year, old, mia, kate, first, ...   \n",
       "720  [175, million, share, traded, big, board, 7, p...   \n",
       "721  [mr, berlusconi, accused, bribing, judge, infl...   \n",
       "722  [added, solely, american, principle, exclusive...   \n",
       "723  [memory, also, live, bloody, debacle, somalia,...   \n",
       "\n",
       "                                         Text_Cleaned2  \\\n",
       "0    [acting, new, police, chief, francisco, ortiz,...   \n",
       "1    [report, shows, drugs, sold, canadian, pharmac...   \n",
       "2    [two, week, transition, period, begin, later, ...   \n",
       "3    [like, viacom, general, electric, seen, less, ...   \n",
       "4    [another, disaster, 62, spanish, peacekeepers,...   \n",
       "..                                                 ...   \n",
       "719  [winslet, 28, three, year, old, daughter, mia,...   \n",
       "720  [1, 6, billion, shares, traded, big, board, 17...   \n",
       "721  [mr, berlusconi, accused, bribing, judges, inf...   \n",
       "722  [solely, american, principles, exclusively, we...   \n",
       "723  [memories, also, live, bloody, debacle, somali...   \n",
       "\n",
       "                                      lemmatized_text2  \\\n",
       "0    [acting, new, police, chief, francisco, ortiz,...   \n",
       "1    [report, show, drug, sold, canadian, pharmacy,...   \n",
       "2    [two, week, transition, period, begin, later, ...   \n",
       "3    [like, viacom, general, electric, seen, le, en...   \n",
       "4    [another, disaster, 62, spanish, peacekeeper, ...   \n",
       "..                                                 ...   \n",
       "719  [winslet, 28, three, year, old, daughter, mia,...   \n",
       "720  [1, 6, billion, share, traded, big, board, 17,...   \n",
       "721  [mr, berlusconi, accused, bribing, judge, infl...   \n",
       "722  [solely, american, principle, exclusively, wes...   \n",
       "723  [memory, also, live, bloody, debacle, somalia,...   \n",
       "\n",
       "     cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                   0.534522           0.750000       0.138889   \n",
       "1                   0.802955           0.823529       0.151261   \n",
       "2                   0.625000           1.000000       0.000000   \n",
       "3                   0.725241           0.785714       0.175325   \n",
       "4                   0.585369           0.846154       0.097902   \n",
       "..                       ...                ...            ...   \n",
       "719                 0.694365           0.857143       0.107143   \n",
       "720                 0.462910           0.857143       0.071429   \n",
       "721                 0.716115           0.866667       0.102564   \n",
       "722                 0.771517           0.857143       0.119048   \n",
       "723                 0.828079           0.933333       0.057143   \n",
       "\n",
       "     overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0          0.238095             0.400892                  0.890871   \n",
       "1          0.387097             0.661257                  0.860309   \n",
       "2          0.312500             0.625000                  1.000000   \n",
       "3          0.360000             0.569832                  0.886405   \n",
       "4          0.291667             0.495313                  0.919866   \n",
       "..              ...                  ...                       ...   \n",
       "719        0.346154             0.595170                  0.925820   \n",
       "720        0.230769             0.396780                  0.925820   \n",
       "721        0.357143             0.620633                  0.930949   \n",
       "722        0.384615             0.661300                  0.925820   \n",
       "723        0.413793             0.772873                  0.966092   \n",
       "\n",
       "     jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \\\n",
       "0                    0.333333             0.333333           0.519179   \n",
       "1                    0.705882             0.705882           0.757358   \n",
       "2                    0.454545             0.454545           0.636364   \n",
       "3                    0.562500             0.600000           0.682968   \n",
       "4                    0.411765             0.411765           0.581132   \n",
       "..                        ...                  ...                ...   \n",
       "719                  0.529412             0.529412           0.661548   \n",
       "720                  0.300000             0.300000           0.508607   \n",
       "721                  0.555556             0.555556           0.680687   \n",
       "722                  0.625000             0.625000           0.725273   \n",
       "723                  0.705882             0.812500           0.828158   \n",
       "\n",
       "     overall_similarity_path_semantic  overall_similarity_wup_semantic  \\\n",
       "0                            0.584580                         0.482766   \n",
       "1                            0.855122                         0.803763   \n",
       "2                            0.743750                         0.684524   \n",
       "3                            0.796260                         0.749333   \n",
       "4                            0.680159                         0.603472   \n",
       "..                                ...                              ...   \n",
       "719                          0.638645                         0.598718   \n",
       "720                          0.720496                         0.592949   \n",
       "721                          0.717347                         0.706633   \n",
       "722                          0.813187                         0.794872   \n",
       "723                          0.960591                         0.928161   \n",
       "\n",
       "     overall_similarity_combined_semantic  \n",
       "0                                0.526301  \n",
       "1                                0.828098  \n",
       "2                                0.713095  \n",
       "3                                0.770524  \n",
       "4                                0.641237  \n",
       "..                                    ...  \n",
       "719                              0.614469  \n",
       "720                              0.656723  \n",
       "721                              0.711990  \n",
       "722                              0.804029  \n",
       "723                              0.943897  \n",
       "\n",
       "[724 rows x 20 columns]"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_df['scores'] = list(map(semantic_similarities, dev_df.lemmatized_text1, dev_df.lemmatized_text2))\n",
    "dev_df[['overall_similarity_path_semantic', 'overall_similarity_wup_semantic', 'overall_similarity_combined_semantic']] = pd.DataFrame(dev_df.scores.tolist(), index= dev_df.index)\n",
    "dev_df.drop(['scores'], axis=1, inplace=True)\n",
    "dev_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c1042199-8a40-41ae-9f68-9e2f68369d21",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "      <th>overall_similarity_path_semantic</th>\n",
       "      <th>overall_similarity_wup_semantic</th>\n",
       "      <th>overall_similarity_combined_semantic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dev_id_0</td>\n",
       "      <td>Local police authorities are treating the expl...</td>\n",
       "      <td>Acting New Haven Police Chief Francisco Ortiz ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[local, police, authorities, treating, explosi...</td>\n",
       "      <td>[local, police, authority, treating, explosion...</td>\n",
       "      <td>[acting, new, police, chief, francisco, ortiz,...</td>\n",
       "      <td>[acting, new, police, chief, francisco, ortiz,...</td>\n",
       "      <td>0.534522</td>\n",
       "      <td>0.861111</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>0.400892</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.519179</td>\n",
       "      <td>0.584580</td>\n",
       "      <td>0.482766</td>\n",
       "      <td>0.526301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dev_id_1</td>\n",
       "      <td>The report shows that drugs sold in Canadian p...</td>\n",
       "      <td>The report shows that drugs sold in Canadian p...</td>\n",
       "      <td>1</td>\n",
       "      <td>[report, shows, drugs, sold, canadian, pharmac...</td>\n",
       "      <td>[report, show, drug, sold, canadian, pharmacy,...</td>\n",
       "      <td>[report, shows, drugs, sold, canadian, pharmac...</td>\n",
       "      <td>[report, show, drug, sold, canadian, pharmacy,...</td>\n",
       "      <td>0.802955</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.612903</td>\n",
       "      <td>0.661257</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.757358</td>\n",
       "      <td>0.855122</td>\n",
       "      <td>0.803763</td>\n",
       "      <td>0.828098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dev_id_2</td>\n",
       "      <td>The transition is slated to begin no later tha...</td>\n",
       "      <td>A two-week transition period will begin no lat...</td>\n",
       "      <td>1</td>\n",
       "      <td>[transition, slated, begin, later, june, 7, da...</td>\n",
       "      <td>[transition, slated, begin, later, june, 7, da...</td>\n",
       "      <td>[two, week, transition, period, begin, later, ...</td>\n",
       "      <td>[two, week, transition, period, begin, later, ...</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.687500</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.743750</td>\n",
       "      <td>0.684524</td>\n",
       "      <td>0.713095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dev_id_3</td>\n",
       "      <td>Like Viacom , GE -- parent of NBC -- is also s...</td>\n",
       "      <td>Like Viacom , General Electric is seen as a le...</td>\n",
       "      <td>1</td>\n",
       "      <td>[like, viacom, ge, parent, nbc, also, seen, le...</td>\n",
       "      <td>[like, viacom, ge, parent, nbc, also, seen, le...</td>\n",
       "      <td>[like, viacom, general, electric, seen, less, ...</td>\n",
       "      <td>[like, viacom, general, electric, seen, le, en...</td>\n",
       "      <td>0.725241</td>\n",
       "      <td>0.824675</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.569832</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.682968</td>\n",
       "      <td>0.796260</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>0.770524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dev_id_4</td>\n",
       "      <td>Last month , 62 Spanish peacekeepers died when...</td>\n",
       "      <td>In another disaster , 62 Spanish peacekeepers ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[last, month, 62, spanish, peacekeepers, died,...</td>\n",
       "      <td>[last, month, 62, spanish, peacekeeper, died, ...</td>\n",
       "      <td>[another, disaster, 62, spanish, peacekeepers,...</td>\n",
       "      <td>[another, disaster, 62, spanish, peacekeeper, ...</td>\n",
       "      <td>0.585369</td>\n",
       "      <td>0.902098</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>0.495313</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.581132</td>\n",
       "      <td>0.680159</td>\n",
       "      <td>0.603472</td>\n",
       "      <td>0.641237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>dev_id_719</td>\n",
       "      <td>He is a brother to three-year-old Mia , from K...</td>\n",
       "      <td>Winslet , 28 , has a three-year-old daughter M...</td>\n",
       "      <td>0</td>\n",
       "      <td>[brother, three, year, old, mia, kate, first, ...</td>\n",
       "      <td>[brother, three, year, old, mia, kate, first, ...</td>\n",
       "      <td>[winslet, 28, three, year, old, daughter, mia,...</td>\n",
       "      <td>[winslet, 28, three, year, old, daughter, mia,...</td>\n",
       "      <td>0.694365</td>\n",
       "      <td>0.892857</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.595170</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.529412</td>\n",
       "      <td>0.661548</td>\n",
       "      <td>0.638645</td>\n",
       "      <td>0.598718</td>\n",
       "      <td>0.614469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>dev_id_720</td>\n",
       "      <td>Some 175 million shares traded on the Big Boar...</td>\n",
       "      <td>Some 1.6 billion shares traded on the Big Boar...</td>\n",
       "      <td>0</td>\n",
       "      <td>[175, million, shares, traded, big, board, 7, ...</td>\n",
       "      <td>[175, million, share, traded, big, board, 7, p...</td>\n",
       "      <td>[1, 6, billion, shares, traded, big, board, 17...</td>\n",
       "      <td>[1, 6, billion, share, traded, big, board, 17,...</td>\n",
       "      <td>0.462910</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.396780</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.508607</td>\n",
       "      <td>0.720496</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>0.656723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>dev_id_721</td>\n",
       "      <td>Mr Berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>Mr Berlusconi is accused of bribing judges to ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judges, inf...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judge, infl...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judges, inf...</td>\n",
       "      <td>[mr, berlusconi, accused, bribing, judge, infl...</td>\n",
       "      <td>0.716115</td>\n",
       "      <td>0.897436</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.620633</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.680687</td>\n",
       "      <td>0.717347</td>\n",
       "      <td>0.706633</td>\n",
       "      <td>0.711990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>dev_id_722</td>\n",
       "      <td>He added that those \" are not solely American ...</td>\n",
       "      <td>\" These are not solely American principles nor...</td>\n",
       "      <td>1</td>\n",
       "      <td>[added, solely, american, principles, exclusiv...</td>\n",
       "      <td>[added, solely, american, principle, exclusive...</td>\n",
       "      <td>[solely, american, principles, exclusively, we...</td>\n",
       "      <td>[solely, american, principle, exclusively, wes...</td>\n",
       "      <td>0.771517</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.661300</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.725273</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.804029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>723</th>\n",
       "      <td>dev_id_723</td>\n",
       "      <td>Memories also live on of the bloody debacle in...</td>\n",
       "      <td>Memories also live on of a bloody debacle in S...</td>\n",
       "      <td>1</td>\n",
       "      <td>[memories, also, live, bloody, debacle, somali...</td>\n",
       "      <td>[memory, also, live, bloody, debacle, somalia,...</td>\n",
       "      <td>[memories, also, live, bloody, debacle, somali...</td>\n",
       "      <td>[memory, also, live, bloody, debacle, somalia,...</td>\n",
       "      <td>0.828079</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.586207</td>\n",
       "      <td>0.772873</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.828158</td>\n",
       "      <td>0.960591</td>\n",
       "      <td>0.928161</td>\n",
       "      <td>0.943897</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>724 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                                          sentence1  \\\n",
       "0      dev_id_0  Local police authorities are treating the expl...   \n",
       "1      dev_id_1  The report shows that drugs sold in Canadian p...   \n",
       "2      dev_id_2  The transition is slated to begin no later tha...   \n",
       "3      dev_id_3  Like Viacom , GE -- parent of NBC -- is also s...   \n",
       "4      dev_id_4  Last month , 62 Spanish peacekeepers died when...   \n",
       "..          ...                                                ...   \n",
       "719  dev_id_719  He is a brother to three-year-old Mia , from K...   \n",
       "720  dev_id_720  Some 175 million shares traded on the Big Boar...   \n",
       "721  dev_id_721  Mr Berlusconi is accused of bribing judges to ...   \n",
       "722  dev_id_722  He added that those \" are not solely American ...   \n",
       "723  dev_id_723  Memories also live on of the bloody debacle in...   \n",
       "\n",
       "                                             sentence2  classification  \\\n",
       "0    Acting New Haven Police Chief Francisco Ortiz ...               0   \n",
       "1    The report shows that drugs sold in Canadian p...               1   \n",
       "2    A two-week transition period will begin no lat...               1   \n",
       "3    Like Viacom , General Electric is seen as a le...               1   \n",
       "4    In another disaster , 62 Spanish peacekeepers ...               1   \n",
       "..                                                 ...             ...   \n",
       "719  Winslet , 28 , has a three-year-old daughter M...               0   \n",
       "720  Some 1.6 billion shares traded on the Big Boar...               0   \n",
       "721  Mr Berlusconi is accused of bribing judges to ...               1   \n",
       "722  \" These are not solely American principles nor...               1   \n",
       "723  Memories also live on of a bloody debacle in S...               1   \n",
       "\n",
       "                                         Text_Cleaned1  \\\n",
       "0    [local, police, authorities, treating, explosi...   \n",
       "1    [report, shows, drugs, sold, canadian, pharmac...   \n",
       "2    [transition, slated, begin, later, june, 7, da...   \n",
       "3    [like, viacom, ge, parent, nbc, also, seen, le...   \n",
       "4    [last, month, 62, spanish, peacekeepers, died,...   \n",
       "..                                                 ...   \n",
       "719  [brother, three, year, old, mia, kate, first, ...   \n",
       "720  [175, million, shares, traded, big, board, 7, ...   \n",
       "721  [mr, berlusconi, accused, bribing, judges, inf...   \n",
       "722  [added, solely, american, principles, exclusiv...   \n",
       "723  [memories, also, live, bloody, debacle, somali...   \n",
       "\n",
       "                                      lemmatized_text1  \\\n",
       "0    [local, police, authority, treating, explosion...   \n",
       "1    [report, show, drug, sold, canadian, pharmacy,...   \n",
       "2    [transition, slated, begin, later, june, 7, da...   \n",
       "3    [like, viacom, ge, parent, nbc, also, seen, le...   \n",
       "4    [last, month, 62, spanish, peacekeeper, died, ...   \n",
       "..                                                 ...   \n",
       "719  [brother, three, year, old, mia, kate, first, ...   \n",
       "720  [175, million, share, traded, big, board, 7, p...   \n",
       "721  [mr, berlusconi, accused, bribing, judge, infl...   \n",
       "722  [added, solely, american, principle, exclusive...   \n",
       "723  [memory, also, live, bloody, debacle, somalia,...   \n",
       "\n",
       "                                         Text_Cleaned2  \\\n",
       "0    [acting, new, police, chief, francisco, ortiz,...   \n",
       "1    [report, shows, drugs, sold, canadian, pharmac...   \n",
       "2    [two, week, transition, period, begin, later, ...   \n",
       "3    [like, viacom, general, electric, seen, less, ...   \n",
       "4    [another, disaster, 62, spanish, peacekeepers,...   \n",
       "..                                                 ...   \n",
       "719  [winslet, 28, three, year, old, daughter, mia,...   \n",
       "720  [1, 6, billion, shares, traded, big, board, 17...   \n",
       "721  [mr, berlusconi, accused, bribing, judges, inf...   \n",
       "722  [solely, american, principles, exclusively, we...   \n",
       "723  [memories, also, live, bloody, debacle, somali...   \n",
       "\n",
       "                                      lemmatized_text2  \\\n",
       "0    [acting, new, police, chief, francisco, ortiz,...   \n",
       "1    [report, show, drug, sold, canadian, pharmacy,...   \n",
       "2    [two, week, transition, period, begin, later, ...   \n",
       "3    [like, viacom, general, electric, seen, le, en...   \n",
       "4    [another, disaster, 62, spanish, peacekeeper, ...   \n",
       "..                                                 ...   \n",
       "719  [winslet, 28, three, year, old, daughter, mia,...   \n",
       "720  [1, 6, billion, share, traded, big, board, 17,...   \n",
       "721  [mr, berlusconi, accused, bribing, judge, infl...   \n",
       "722  [solely, american, principle, exclusively, wes...   \n",
       "723  [memory, also, live, bloody, debacle, somalia,...   \n",
       "\n",
       "     cosine_similarity_score  overlap_score  overlap2_score  \\\n",
       "0                   0.534522       0.861111        0.761905   \n",
       "1                   0.802955       0.848739        0.612903   \n",
       "2                   0.625000       1.000000        0.687500   \n",
       "3                   0.725241       0.824675        0.640000   \n",
       "4                   0.585369       0.902098        0.708333   \n",
       "..                       ...            ...             ...   \n",
       "719                 0.694365       0.892857        0.653846   \n",
       "720                 0.462910       0.928571        0.769231   \n",
       "721                 0.716115       0.897436        0.642857   \n",
       "722                 0.771517       0.880952        0.615385   \n",
       "723                 0.828079       0.942857        0.586207   \n",
       "\n",
       "     cosine/length_ratio  jaccard_similarity_score  lemma_jaccard_score  \\\n",
       "0               0.400892                  0.333333             0.333333   \n",
       "1               0.661257                  0.705882             0.705882   \n",
       "2               0.625000                  0.454545             0.454545   \n",
       "3               0.569832                  0.562500             0.600000   \n",
       "4               0.495313                  0.411765             0.411765   \n",
       "..                   ...                       ...                  ...   \n",
       "719             0.595170                  0.529412             0.529412   \n",
       "720             0.396780                  0.300000             0.300000   \n",
       "721             0.620633                  0.555556             0.555556   \n",
       "722             0.661300                  0.625000             0.625000   \n",
       "723             0.772873                  0.705882             0.812500   \n",
       "\n",
       "     overall_sim_score  overall_similarity_path_semantic  \\\n",
       "0             0.519179                          0.584580   \n",
       "1             0.757358                          0.855122   \n",
       "2             0.636364                          0.743750   \n",
       "3             0.682968                          0.796260   \n",
       "4             0.581132                          0.680159   \n",
       "..                 ...                               ...   \n",
       "719           0.661548                          0.638645   \n",
       "720           0.508607                          0.720496   \n",
       "721           0.680687                          0.717347   \n",
       "722           0.725273                          0.813187   \n",
       "723           0.828158                          0.960591   \n",
       "\n",
       "     overall_similarity_wup_semantic  overall_similarity_combined_semantic  \n",
       "0                           0.482766                              0.526301  \n",
       "1                           0.803763                              0.828098  \n",
       "2                           0.684524                              0.713095  \n",
       "3                           0.749333                              0.770524  \n",
       "4                           0.603472                              0.641237  \n",
       "..                               ...                                   ...  \n",
       "719                         0.598718                              0.614469  \n",
       "720                         0.592949                              0.656723  \n",
       "721                         0.706633                              0.711990  \n",
       "722                         0.794872                              0.804029  \n",
       "723                         0.928161                              0.943897  \n",
       "\n",
       "[724 rows x 18 columns]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dev_df['overlap_score'] = list(map(overlap_score, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "# dev_df['overlap2_score'] = list(map(overlap2_score, dev_df.Text_Cleaned1, dev_df.Text_Cleaned2))\n",
    "# dev_df['overlap_score'] = 1 - dev_df['overlap_score']\n",
    "# dev_df['overlap2_score'] = 1 - dev_df['overlap2_score']\n",
    "# dev_df.drop(['length_similarity', 'cosine_similarity_score2'], axis=1, inplace=True)\n",
    "# dev_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15b5f8d-6881-4f3a-af47-8a9960762309",
   "metadata": {},
   "source": [
    "## Exporting Pre-Processed Data Files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "0624b591-b70a-4726-b37a-51a259336234",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.to_csv('../Data2/train_df.csv', index = False)\n",
    "new_train_df.to_csv('../Data2/train_df_randomUnder.csv', index = False)\n",
    "new_train_df_clean.to_csv('../Data2/train_df_no_outliers.csv', index = False)\n",
    "subset0.to_csv('../Data2/subset0.csv', index = False)\n",
    "subset1.to_csv('../Data2/subset1.csv', index = False)\n",
    "train_df2.to_csv('../Data2/train_df2.csv', index = False)\n",
    "subset0_2.to_csv('../Data2/subset0_2.csv', index = False)\n",
    "subset1_2.to_csv('../Data2/subset1_2.csv', index = False)\n",
    "new_train_df_2.to_csv('../Data2/train_df2_randomUnder.csv', index = False)\n",
    "new_train_df_clean_2.to_csv('../Data2/train_df2_no_outliers.csv', index = False)\n",
    "missing_train.to_csv('../Data2/missing_train.csv', index = False)\n",
    "missing.to_csv('../Data2/Missing.csv', index = False)\n",
    "new_train_df_clean_Missing.to_csv('../Data2/missing_train_df_no_outliers.csv', index = False)\n",
    "new_train_df_Missing.to_csv('../Data2/missing_train_df_randomUnder.csv', index = False)\n",
    "dev_df.to_csv('../Data2/dev_df.csv', index = False)\n",
    "\n",
    "new_train_df_clean_randomUnder.to_csv('../Data2/train_df_no_outliers_randomUnder.csv', index = False)\n",
    "new_train_df_2_clean_randomUnder.to_csv('../Data2/train_df2_no_outliers_randomUnder.csv', index = False)\n",
    "missing_clean_randomUnder.to_csv('../Data2/missing_train_df_no_outliers_randomUnder.csv', index = False)\n",
    "train_df3.to_csv('../Data2/train_df_3.csv', index = False)\n",
    "new_train_df_3.to_csv('../Data2/train_df3_randomUnder.csv', index = False)\n",
    "new_train_df_clean_3.to_csv('../Data2/train_df3_no_outliers.csv', index = False)\n",
    "new_train_df_3_clean_randomUnder.to_csv('../Data2/train_df3_no_outliers_randomUnder.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "090d1174-cbd2-4e2d-a079-c7dae3cb1f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../Data/train_df.csv')\n",
    "new_train_df = pd.read_csv('../Data/train_df_randomUnder.csv')\n",
    "new_train_df_clean = pd.read_csv('../Data/train_df_no_outliers.csv')\n",
    "subset0 = pd.read_csv('../Data/subset0.csv')\n",
    "subset1 = pd.read_csv('../Data/subset1.csv')\n",
    "train_df2 = pd.read_csv('../Data/train_df2.csv')\n",
    "subset0_2 = pd.read_csv('../Data/subset0_2.csv')\n",
    "subset1_2 = pd.read_csv('../Data/subset1_2.csv')\n",
    "new_train_df_2 = pd.read_csv('../Data/train_df2_randomUnder.csv')\n",
    "new_train_df_clean_2 = pd.read_csv('../Data/train_df2_no_outliers.csv')\n",
    "missing_train = pd.read_csv('../Data/missing_train.csv')\n",
    "new_train_df_clean_Missing = pd.read_csv('../Data/missing_train_df_no_outliers.csv')\n",
    "new_train_df_Missing = pd.read_csv('../Data/missing_train_df_randomUnder.csv')\n",
    "dev_df = pd.read_csv('../Data/dev_df.csv')\n",
    "\n",
    "new_train_df_clean_randomUnder = pd.read_csv('../Data/train_df_no_outliers_randomUnder.csv')\n",
    "new_train_df_2_clean_randomUnder = pd.read_csv('../Data/train_df2_no_outliers_randomUnder.csv')\n",
    "missing_clean_randomUnder = pd.read_csv('../Data/missing_train_df_no_outliers_randomUnder.csv')\n",
    "train_df3 = pd.read_csv('../Data/train_df_3.csv')\n",
    "new_train_df_3 = pd.read_csv('../Data/train_df3_randomUnder.csv')\n",
    "new_train_df_clean_3 = pd.read_csv('../Data/train_df3_no_outliers.csv')\n",
    "new_train_df_3_clean_randomUnder = pd.read_csv('../Data/train_df3_no_outliers_randomUnder.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "284dc8a8-5278-459a-a1fa-179d8a99ccb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df = new_train_df[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_clean = new_train_df_clean[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "subset0 = subset0[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "subset1 = subset1[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "train_df2 = train_df2[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "subset0_2 = subset0_2[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "subset1_2 = subset1_2[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_2 = new_train_df_2[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_clean_2 = new_train_df_clean_2[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "missing_train = missing_train[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_clean_Missing = new_train_df_clean_Missing[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_Missing = new_train_df_Missing[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "dev_df = dev_df[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "\n",
    "new_train_df_clean_randomUnder = new_train_df_clean_randomUnder[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_2_clean_randomUnder = new_train_df_2_clean_randomUnder[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "missing_clean_randomUnder = missing_clean_randomUnder[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "train_df3 = train_df3[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_3 = new_train_df_3[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_clean_3 = new_train_df_clean_3[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]\n",
    "new_train_df_3_clean_randomUnder = new_train_df_3_clean_randomUnder[['classification','lemma_jaccard_score', 'overall_sim_score', 'cosine/length_ratio', 'cosine_similarity_trigrams', 'jaccard_similarity_score', 'overlap_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "1af0c9ee-136d-4ea4-834d-77d567a58ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['classification', 'lemma_jaccard_score', 'overall_sim_score',\n",
       "       'cosine/length_ratio', 'cosine_similarity_trigrams',\n",
       "       'jaccard_similarity_score', 'overlap_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "fa218c61-2d27-4ef3-b177-65299a440927",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_df['lemmatized_text1'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "bbbf5932-67d4-4093-9193-372de2c78bb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>classification</th>\n",
       "      <th>Text_Cleaned1</th>\n",
       "      <th>lemmatized_text1</th>\n",
       "      <th>Text_Cleaned2</th>\n",
       "      <th>lemmatized_text2</th>\n",
       "      <th>cosine_similarity_score</th>\n",
       "      <th>length_similarity</th>\n",
       "      <th>overlap_score</th>\n",
       "      <th>overlap2_score</th>\n",
       "      <th>cosine/length_ratio</th>\n",
       "      <th>cosine_similarity_score2</th>\n",
       "      <th>jaccard_similarity_score</th>\n",
       "      <th>lemma_jaccard_score</th>\n",
       "      <th>overall_sim_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_id_0</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>The Democratic candidates also began announcin...</td>\n",
       "      <td>1</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>[democratic, candidates, also, began, announci...</td>\n",
       "      <td>[democratic, candidate, also, began, announcin...</td>\n",
       "      <td>0.909509</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.055147</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.856008</td>\n",
       "      <td>0.970143</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_id_1</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>The woman was exposed to the SARS virus while ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>[woman, exposed, sars, virus, hospital, health...</td>\n",
       "      <td>0.904534</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.804030</td>\n",
       "      <td>0.954786</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.937500</td>\n",
       "      <td>0.943262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_id_2</td>\n",
       "      <td>He said the problem needs to be corrected befo...</td>\n",
       "      <td>He said the prob lem needs to be corrected bef...</td>\n",
       "      <td>1</td>\n",
       "      <td>[said, problem, needs, corrected, space, shutt...</td>\n",
       "      <td>[said, problem, need, corrected, space, shuttl...</td>\n",
       "      <td>[said, prob, lem, needs, corrected, space, shu...</td>\n",
       "      <td>[said, prob, lem, need, corrected, space, shut...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.712121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_id_3</td>\n",
       "      <td>A representative for Phoenix-based U-Haul decl...</td>\n",
       "      <td>Anthony Citrano , a representative for WhenU ,...</td>\n",
       "      <td>0</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[representative, phoenix, based, u, haul, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>[anthony, citrano, representative, whenu, decl...</td>\n",
       "      <td>0.455842</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.207792</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.290081</td>\n",
       "      <td>0.797724</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.456384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_id_4</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>The biggest threat to order seemed to be looti...</td>\n",
       "      <td>1</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>[biggest, threat, order, seemed, looting, crim...</td>\n",
       "      <td>0.721688</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>0.541266</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.659046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4072</th>\n",
       "      <td>train_id_4072</td>\n",
       "      <td>Axelrod died in his sleep of heart failure , s...</td>\n",
       "      <td>Axelrod died of heart failure while asleep at ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, sleep, heart, failure, said, d...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>[axelrod, died, heart, failure, asleep, los, a...</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.604367</td>\n",
       "      <td>0.886405</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.684357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>train_id_4073</td>\n",
       "      <td>Saddam 's other son , Odai , surrendered Frida...</td>\n",
       "      <td>Hussein 's other son , Uday , surrendered yest...</td>\n",
       "      <td>1</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[saddam, son, odai, surrendered, friday, ameri...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>[hussein, son, uday, surrendered, yesterday, a...</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.655678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>train_id_4074</td>\n",
       "      <td>If Senator Clinton does decide to run in 2008 ...</td>\n",
       "      <td>If Mrs Clinton does decide to contest the 2008...</td>\n",
       "      <td>1</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[senator, clinton, decide, run, 2008, cannot, ...</td>\n",
       "      <td>[mrs, clinton, decide, contest, 2008, election...</td>\n",
       "      <td>[mr, clinton, decide, contest, 2008, election,...</td>\n",
       "      <td>0.819892</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.064103</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.756823</td>\n",
       "      <td>0.968963</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.799178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>train_id_4075</td>\n",
       "      <td>The Iranian refugee who sewed up his eyes , li...</td>\n",
       "      <td>An Iranian Kurd who stitched up his eyes , lip...</td>\n",
       "      <td>1</td>\n",
       "      <td>[iranian, refugee, sewed, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, refugee, sewed, eye, lip, ear, prote...</td>\n",
       "      <td>[iranian, kurd, stitched, eyes, lips, ears, pr...</td>\n",
       "      <td>[iranian, kurd, stitched, eye, lip, ear, prote...</td>\n",
       "      <td>0.560449</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.044872</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.517337</td>\n",
       "      <td>0.960769</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.579516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4076</th>\n",
       "      <td>train_id_4076</td>\n",
       "      <td>Gemstar 's shares gathered up 2.6 percent , ad...</td>\n",
       "      <td>Gemstar shares moved higher on the news , clos...</td>\n",
       "      <td>1</td>\n",
       "      <td>[gemstar, shares, gathered, 2, 6, percent, add...</td>\n",
       "      <td>[gemstar, share, gathered, 2, 6, percent, addi...</td>\n",
       "      <td>[gemstar, shares, moved, higher, news, closing...</td>\n",
       "      <td>[gemstar, share, moved, higher, news, closing,...</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.411765</td>\n",
       "      <td>0.607843</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4077 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                          sentence1  \\\n",
       "0        train_id_0  The Democratic candidates also began announcin...   \n",
       "1        train_id_1  The woman was exposed to the SARS virus while ...   \n",
       "2        train_id_2  He said the problem needs to be corrected befo...   \n",
       "3        train_id_3  A representative for Phoenix-based U-Haul decl...   \n",
       "4        train_id_4  The biggest threat to order seemed to be looti...   \n",
       "...             ...                                                ...   \n",
       "4072  train_id_4072  Axelrod died in his sleep of heart failure , s...   \n",
       "4073  train_id_4073  Saddam 's other son , Odai , surrendered Frida...   \n",
       "4074  train_id_4074  If Senator Clinton does decide to run in 2008 ...   \n",
       "4075  train_id_4075  The Iranian refugee who sewed up his eyes , li...   \n",
       "4076  train_id_4076  Gemstar 's shares gathered up 2.6 percent , ad...   \n",
       "\n",
       "                                              sentence2  classification  \\\n",
       "0     The Democratic candidates also began announcin...               1   \n",
       "1     The woman was exposed to the SARS virus while ...               1   \n",
       "2     He said the prob lem needs to be corrected bef...               1   \n",
       "3     Anthony Citrano , a representative for WhenU ,...               0   \n",
       "4     The biggest threat to order seemed to be looti...               1   \n",
       "...                                                 ...             ...   \n",
       "4072  Axelrod died of heart failure while asleep at ...               1   \n",
       "4073  Hussein 's other son , Uday , surrendered yest...               1   \n",
       "4074  If Mrs Clinton does decide to contest the 2008...               1   \n",
       "4075  An Iranian Kurd who stitched up his eyes , lip...               1   \n",
       "4076  Gemstar shares moved higher on the news , clos...               1   \n",
       "\n",
       "                                          Text_Cleaned1  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, needs, corrected, space, shutt...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, gathered, 2, 6, percent, add...   \n",
       "\n",
       "                                       lemmatized_text1  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, problem, need, corrected, space, shuttl...   \n",
       "3     [representative, phoenix, based, u, haul, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, sleep, heart, failure, said, d...   \n",
       "4073  [saddam, son, odai, surrendered, friday, ameri...   \n",
       "4074  [senator, clinton, decide, run, 2008, cannot, ...   \n",
       "4075  [iranian, refugee, sewed, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, gathered, 2, 6, percent, addi...   \n",
       "\n",
       "                                          Text_Cleaned2  \\\n",
       "0     [democratic, candidates, also, began, announci...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, needs, corrected, space, shu...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mrs, clinton, decide, contest, 2008, election...   \n",
       "4075  [iranian, kurd, stitched, eyes, lips, ears, pr...   \n",
       "4076  [gemstar, shares, moved, higher, news, closing...   \n",
       "\n",
       "                                       lemmatized_text2  \\\n",
       "0     [democratic, candidate, also, began, announcin...   \n",
       "1     [woman, exposed, sars, virus, hospital, health...   \n",
       "2     [said, prob, lem, need, corrected, space, shut...   \n",
       "3     [anthony, citrano, representative, whenu, decl...   \n",
       "4     [biggest, threat, order, seemed, looting, crim...   \n",
       "...                                                 ...   \n",
       "4072  [axelrod, died, heart, failure, asleep, los, a...   \n",
       "4073  [hussein, son, uday, surrendered, yesterday, a...   \n",
       "4074  [mr, clinton, decide, contest, 2008, election,...   \n",
       "4075  [iranian, kurd, stitched, eye, lip, ear, prote...   \n",
       "4076  [gemstar, share, moved, higher, news, closing,...   \n",
       "\n",
       "      cosine_similarity_score  length_similarity  overlap_score  \\\n",
       "0                    0.909509           0.941176       0.055147   \n",
       "1                    0.904534           0.888889       0.111111   \n",
       "2                    0.666667           1.000000       0.000000   \n",
       "3                    0.455842           0.636364       0.207792   \n",
       "4                    0.721688           0.750000       0.208333   \n",
       "...                       ...                ...            ...   \n",
       "4072                 0.805823           0.750000       0.222222   \n",
       "4073                 0.600000           1.000000       0.000000   \n",
       "4074                 0.819892           0.923077       0.064103   \n",
       "4075                 0.560449           0.923077       0.044872   \n",
       "4076                 0.583333           1.000000       0.000000   \n",
       "\n",
       "      overlap2_score  cosine/length_ratio  cosine_similarity_score2  \\\n",
       "0           0.454545             0.856008                  0.970143   \n",
       "1           0.470588             0.804030                  0.954786   \n",
       "2           0.333333             0.666667                  1.000000   \n",
       "3           0.222222             0.290081                  0.797724   \n",
       "4           0.357143             0.541266                  0.866025   \n",
       "...              ...                  ...                       ...   \n",
       "4072        0.380952             0.604367                  0.886405   \n",
       "4073        0.300000             0.600000                  1.000000   \n",
       "4074        0.400000             0.756823                  0.968963   \n",
       "4075        0.280000             0.517337                  0.960769   \n",
       "4076        0.291667             0.583333                  1.000000   \n",
       "\n",
       "      jaccard_similarity_score  lemma_jaccard_score  overall_sim_score  \n",
       "0                     0.833333             0.833333           0.878936  \n",
       "1                     0.937500             0.937500           0.943262  \n",
       "2                     0.500000             0.636364           0.712121  \n",
       "3                     0.285714             0.285714           0.456384  \n",
       "4                     0.555556             0.555556           0.659046  \n",
       "...                        ...                  ...                ...  \n",
       "4072                  0.583333             0.583333           0.684357  \n",
       "4073                  0.428571             0.538462           0.655678  \n",
       "4074                  0.714286             0.714286           0.799178  \n",
       "4075                  0.388889             0.388889           0.579516  \n",
       "4076                  0.411765             0.411765           0.607843  \n",
       "\n",
       "[4077 rows x 17 columns]"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c7c9b1-f701-47c8-a9ba-65bfd4725c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
